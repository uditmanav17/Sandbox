{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_QPfPKAkm89N",
        "nLVRP3FAnEEy",
        "ZdtX0CUhnLM4",
        "FPcmuKLquRBe",
        "4aOvaioIueo4",
        "MHLdNJYGvjKY",
        "Jm0Jw1tA0OWu",
        "sZFDmJZR0RMI"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BFhxnNIjtGJ",
        "colab_type": "text"
      },
      "source": [
        "# [Implement Text Classification](https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2-okqufzj9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install texthero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brWJMOWypZrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text wrapping in colab\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guWIYkEGfx7Y",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSCB9pGGf-pL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "dbafa723-8575-49f5-a081-500daa73b552"
      },
      "source": [
        "import texthero as hero\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost\n",
        "import textblob\n",
        "import string as s\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldPOBhpc1Atf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "ae073076-aec8-4be8-b52a-b2d61ef2f39d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsJMeVkvLqko",
        "colab_type": "text"
      },
      "source": [
        "# Texthero \n",
        "* [Github](https://github.com/jbesomi/texthero)\n",
        "* [Docs](https://texthero.org/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT4cxXJ8T-LQ",
        "colab_type": "text"
      },
      "source": [
        "## loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w2znuYKMUC5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "0fff7a67-7d92-45b2-fbb4-040ba7862b14"
      },
      "source": [
        "# import data\n",
        "file_path = r\"https://raw.githubusercontent.com/jbesomi/texthero/master/dataset/bbcsport.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "display(df.head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Claxton hunting first major medal\\n\\nBritish h...</td>\n",
              "      <td>athletics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O'Sullivan could run in Worlds\\n\\nSonia O'Sull...</td>\n",
              "      <td>athletics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Greene sets sights on world title\\n\\nMaurice G...</td>\n",
              "      <td>athletics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IAAF launches fight against drugs\\n\\nThe IAAF ...</td>\n",
              "      <td>athletics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dibaba breaks 5,000m world record\\n\\nEthiopia'...</td>\n",
              "      <td>athletics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text      topic\n",
              "0  Claxton hunting first major medal\\n\\nBritish h...  athletics\n",
              "1  O'Sullivan could run in Worlds\\n\\nSonia O'Sull...  athletics\n",
              "2  Greene sets sights on world title\\n\\nMaurice G...  athletics\n",
              "3  IAAF launches fight against drugs\\n\\nThe IAAF ...  athletics\n",
              "4  Dibaba breaks 5,000m world record\\n\\nEthiopia'...  athletics"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70XrjJ-vqwAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d1d82674-131c-4696-8cfa-29368e41f357"
      },
      "source": [
        "# make a copy of original dataframe\n",
        "raw_df = df.copy()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OgHWx9HUffU",
        "colab_type": "text"
      },
      "source": [
        "## get distinct labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxZmN-c1MtES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "06e58eec-5beb-4e1f-ad09-9ed47527dc5d"
      },
      "source": [
        "# check values of labels\n",
        "df['topic'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "football     265\n",
              "rugby        147\n",
              "cricket      124\n",
              "athletics    101\n",
              "tennis       100\n",
              "Name: topic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNy0rJiuNS5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "8d1338f8-3aaf-4ba2-d3e7-8ca8e334d00f"
      },
      "source": [
        "# first row before prep\n",
        "df['text'][0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Claxton hunting first major medal\\n\\nBritish hurdler Sarah Claxton is confident she can win her first major medal at next month\\'s European Indoor Championships in Madrid.\\n\\nThe 25-year-old has already smashed the British record over 60m hurdles twice this season, setting a new mark of 7.96 seconds to win the AAAs title. \"I am quite confident,\" said Claxton. \"But I take each race as it comes. \"As long as I keep up my training but not do too much I think there is a chance of a medal.\" Claxton has won the national 60m hurdles title for the past three years but has struggled to translate her domestic success to the international stage. Now, the Scotland-born athlete owns the equal fifth-fastest time in the world this year. And at last week\\'s Birmingham Grand Prix, Claxton left European medal favourite Russian Irina Shevchenko trailing in sixth spot.\\n\\nFor the first time, Claxton has only been preparing for a campaign over the hurdles - which could explain her leap in form. In previous seasons, the 25-year-old also contested the long jump but since moving from Colchester to London she has re-focused her attentions. Claxton will see if her new training regime pays dividends at the European Indoors which take place on 5-6 March.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-9DfAdPSowt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "d26c2396-f486-4848-a3b4-597d087cfe2d"
      },
      "source": [
        "# clean pipeline - https://texthero.org/docs/api/texthero.preprocessing.clean.html#texthero.preprocessing.clean\n",
        "# first row after perp\n",
        "hero.clean(df['text'])[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'claxton hunting first major medal british hurdler sarah claxton confident win first major medal next month european indoor championships madrid year old already smashed british record 60m hurdles twice season setting new mark seconds win aaas title quite confident said claxton take race comes long keep training much think chance medal claxton national 60m hurdles title past three years struggled translate domestic success international stage scotland born athlete owns equal fifth fastest time world year last week birmingham grand prix claxton left european medal favourite russian irina shevchenko trailing sixth spot first time claxton preparing campaign hurdles could explain leap form previous seasons year old also contested long jump since moving colchester london focused attentions claxton see new training regime pays dividends european indoors take place march'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrfZev-PUBSJ",
        "colab_type": "text"
      },
      "source": [
        "## preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37WV1Z82Szqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4422c9fb-85fb-4f56-dc7e-1f942818e7c8"
      },
      "source": [
        "df['text'] = hero.clean(df['text'])\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>claxton hunting first major medal british hurd...</td>\n",
              "      <td>athletics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sullivan could run worlds sonia sullivan indic...</td>\n",
              "      <td>athletics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>greene sets sights world title maurice greene ...</td>\n",
              "      <td>athletics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>iaaf launches fight drugs iaaf athletics world...</td>\n",
              "      <td>athletics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dibaba breaks 000m world record ethiopia tirun...</td>\n",
              "      <td>athletics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text      topic\n",
              "0  claxton hunting first major medal british hurd...  athletics\n",
              "1  sullivan could run worlds sonia sullivan indic...  athletics\n",
              "2  greene sets sights world title maurice greene ...  athletics\n",
              "3  iaaf launches fight drugs iaaf athletics world...  athletics\n",
              "4  dibaba breaks 000m world record ethiopia tirun...  athletics"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEefHVIFUY4F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ac92b195-475b-46ce-c6c2-0af6e1b91909"
      },
      "source": [
        "df2 = df.sample(frac=1) # shuffle dataset\n",
        "df2.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>chelsea denied james heroics brave defensive d...</td>\n",
              "      <td>football</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>hearts oak cotonsport hearts oak set ghanaian ...</td>\n",
              "      <td>football</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>holmes starts gb events kelly holmes start ser...</td>\n",
              "      <td>athletics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>549</th>\n",
              "      <td>england coach faces rap row england coach andy...</td>\n",
              "      <td>rugby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>703</th>\n",
              "      <td>officials respond court row australian tennis ...</td>\n",
              "      <td>tennis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text      topic\n",
              "269  chelsea denied james heroics brave defensive d...   football\n",
              "349  hearts oak cotonsport hearts oak set ghanaian ...   football\n",
              "51   holmes starts gb events kelly holmes start ser...  athletics\n",
              "549  england coach faces rap row england coach andy...      rugby\n",
              "703  officials respond court row australian tennis ...     tennis"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmFuN5S5VKU1",
        "colab_type": "text"
      },
      "source": [
        "## Stratified sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE5C1TZMVNn-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "c558a643-850f-4106-878e-ccf9ddc57a12"
      },
      "source": [
        "# first split data and labels\n",
        "X = df2.pop('text')\n",
        "display(X[:10])\n",
        "y = df2.pop('topic')\n",
        "print(y[:10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "269    chelsea denied james heroics brave defensive d...\n",
              "349    hearts oak cotonsport hearts oak set ghanaian ...\n",
              "51     holmes starts gb events kelly holmes start ser...\n",
              "549    england coach faces rap row england coach andy...\n",
              "703    officials respond court row australian tennis ...\n",
              "248    parry relishes anfield challenge bbc sport ref...\n",
              "113    england slump defeat fourth one day internatio...\n",
              "222    ecb reveals county one day revamp england wale...\n",
              "62     holmes urged compete worlds jolanda ceplak urg...\n",
              "27     campbell extend sprint career darren campbell ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "269     football\n",
            "349     football\n",
            "51     athletics\n",
            "549        rugby\n",
            "703       tennis\n",
            "248     football\n",
            "113      cricket\n",
            "222      cricket\n",
            "62     athletics\n",
            "27     athletics\n",
            "Name: topic, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pieQ5e4TgR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "2658e937-4eea-40dc-d6c7-8266fa1054c1"
      },
      "source": [
        "# use stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.4, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"X_train.shape - {X_train.shape}\")\n",
        "print(f\"X_test.shape - {X_test.shape}\")\n",
        "print(f\"y_train.shape - {y_train.shape}\")\n",
        "print(f\"y_test.shape - {y_test.shape}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "X_train.shape - (442,)\n",
            "X_test.shape - (295,)\n",
            "y_train.shape - (442,)\n",
            "y_test.shape - (295,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btpW_WrOaHbB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "58a6fb6b-ef38-4408-d29c-20cfb9113b1a"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "football     159\n",
              "rugby         88\n",
              "cricket       74\n",
              "athletics     61\n",
              "tennis        60\n",
              "Name: topic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7oKZyjfhiSt",
        "colab_type": "text"
      },
      "source": [
        "## label encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k66wzOGhd5F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "df5c8f01-31e5-4bbb-a146-782e75de0082"
      },
      "source": [
        "# label encoding\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "print(f\"y_train - {y_train}\")\n",
        "\n",
        "y_test = label_encoder.fit_transform(y_test)\n",
        "print(f\"y_test - {y_test}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "y_train - [0 1 0 2 4 3 1 3 2 2 3 4 0 2 2 0 2 4 2 0 2 2 0 3 2 2 1 2 4 2 0 2 2 2 2 2 2\n",
            " 2 1 4 2 3 3 3 3 1 0 2 2 4 3 4 4 4 2 1 3 1 4 2 1 2 2 2 3 4 3 2 4 2 0 0 1 1\n",
            " 2 1 3 4 4 4 0 4 2 3 1 1 3 4 2 2 2 2 2 1 0 2 1 3 0 3 0 0 3 2 3 1 2 3 2 2 2\n",
            " 1 2 4 1 3 3 4 3 2 4 2 2 2 1 3 2 0 1 1 0 2 1 2 3 2 2 2 1 1 4 2 1 2 2 3 4 3\n",
            " 3 1 0 4 3 2 0 2 2 2 2 0 1 2 1 1 3 2 3 0 4 4 2 2 3 2 0 0 3 2 1 1 1 2 2 2 1\n",
            " 2 3 3 3 0 2 3 2 3 1 1 2 2 0 0 1 2 1 3 3 2 2 0 0 3 2 3 2 4 0 4 2 3 2 2 2 2\n",
            " 2 3 2 2 3 4 1 1 4 4 2 2 4 3 2 2 0 4 0 0 1 2 0 2 3 4 1 2 4 1 0 4 4 1 2 2 4\n",
            " 4 3 0 1 0 4 4 2 2 3 2 2 3 2 1 3 1 1 3 2 0 4 0 3 1 2 3 4 2 3 1 4 0 2 2 3 2\n",
            " 3 0 0 2 4 4 2 3 0 0 3 3 1 4 4 2 2 1 3 2 2 0 3 0 3 1 0 2 2 1 0 3 2 1 3 2 4\n",
            " 3 0 0 2 3 4 3 0 3 2 1 0 2 3 1 0 2 1 2 3 3 2 2 3 0 4 3 2 2 4 1 2 0 2 1 4 0\n",
            " 2 4 1 3 2 3 2 2 2 1 1 4 1 2 0 4 2 2 3 3 3 2 3 1 4 2 2 2 2 1 1 1 4 3 2 2 4\n",
            " 3 2 1 4 3 2 2 4 2 0 2 3 3 2 1 2 2 2 0 1 1 3 0 2 3 2 2 2 0 0 3 1 1 2 1]\n",
            "y_test - [2 0 3 3 2 2 1 2 1 0 2 2 0 3 3 3 4 1 4 1 3 3 3 0 2 2 2 4 2 2 3 4 3 1 4 0 2\n",
            " 1 4 4 1 3 1 3 0 1 2 2 3 2 2 0 2 4 1 3 3 2 4 3 3 3 2 4 3 2 1 0 3 2 4 4 1 1\n",
            " 0 2 2 1 2 1 2 1 3 2 1 2 3 0 1 1 4 3 3 2 0 2 2 4 2 3 0 4 2 2 2 3 3 2 3 3 1\n",
            " 3 1 3 2 0 2 1 3 1 2 2 2 0 3 2 2 0 0 3 0 2 2 2 3 1 2 4 0 1 2 1 2 2 1 4 2 2\n",
            " 2 2 0 0 3 4 0 0 0 2 4 4 1 3 4 1 0 2 1 2 1 2 3 0 0 0 2 2 2 0 4 1 3 0 1 0 0\n",
            " 4 2 2 2 1 2 4 2 1 0 2 3 2 4 2 2 4 1 2 3 4 1 2 0 3 4 2 2 1 3 1 1 2 4 3 1 1\n",
            " 1 3 2 2 2 3 3 4 1 3 2 2 2 4 3 0 4 2 2 1 2 0 2 2 4 4 2 3 2 2 3 3 2 3 2 1 4\n",
            " 0 0 2 2 0 3 3 2 3 4 4 2 4 2 2 4 1 1 2 2 2 1 2 2 3 2 0 2 2 2 3 2 0 3 4 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb9q3u0Lii_C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "61a868d0-e583-4e79-feb6-45c43006b586"
      },
      "source": [
        "# check label encoding\n",
        "print(f\"Classes - {label_encoder.classes_}\")\n",
        "print(f\"Transformations - {label_encoder.transform(label_encoder.classes_)}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Classes - ['athletics' 'cricket' 'football' 'rugby' 'tennis']\n",
            "Transformations - [0 1 2 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0eH2d_KTsr2",
        "colab_type": "text"
      },
      "source": [
        "Now, data is pretty much ready."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRsAPY_0hAM2",
        "colab_type": "text"
      },
      "source": [
        "# Feature Engineering\n",
        "The next step is the feature engineering step. In this step, raw text data will be transformed into feature vectors and new features will be created using the existing dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLDne1-lkDp_",
        "colab_type": "text"
      },
      "source": [
        "## Count Vectors as features\n",
        "Count Vector is a matrix notation of the dataset in which every row represents a document from the corpus, every column represents a term from the corpus, and every cell represents the frequency count of a particular term in a particular document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vor5wetkBY4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "90b5b4a4-e55e-426a-8881-0c21252670c9"
      },
      "source": [
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(X_train)\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "xtrain_count =  count_vect.transform(X_train)\n",
        "# print(f\"xtrain_count - {xtrain_count[0]}\")\n",
        "\n",
        "xvalid_count =  count_vect.transform(X_test)\n",
        "# print(f\"xvalid_count - {xvalid_count[0]}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_aaimlvkQxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8e4f1b1-9fbd-446b-bd1e-31acba17c678"
      },
      "source": [
        "xtrain_count.shape  # (train examples, unique words)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(442, 10333)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg4wzhXWGuHW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "6323174c-f174-4dad-f44b-dfd067b8699f"
      },
      "source": [
        "list(count_vect.vocabulary_.items())[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pittman', 6857),\n",
              " ('drops', 2856),\n",
              " ('coach', 1782),\n",
              " ('uk', 9631),\n",
              " ('base', 882),\n",
              " ('australia', 750),\n",
              " ('world', 10205),\n",
              " ('400m', 67),\n",
              " ('hurdle', 4528),\n",
              " ('champion', 1585)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPZUeBQzHXHj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "outputId": "74ce0776-0b4f-43c6-a70a-122ef7794d3c"
      },
      "source": [
        "print(xtrain_count[0])  # (sentence index, word mapping)  word_count"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "  (0, 67)\t2\n",
            "  (0, 281)\t1\n",
            "  (0, 293)\t1\n",
            "  (0, 341)\t1\n",
            "  (0, 416)\t1\n",
            "  (0, 427)\t1\n",
            "  (0, 622)\t1\n",
            "  (0, 625)\t1\n",
            "  (0, 704)\t1\n",
            "  (0, 705)\t2\n",
            "  (0, 750)\t2\n",
            "  (0, 796)\t2\n",
            "  (0, 882)\t1\n",
            "  (0, 919)\t2\n",
            "  (0, 976)\t1\n",
            "  (0, 996)\t1\n",
            "  (0, 1036)\t1\n",
            "  (0, 1289)\t1\n",
            "  (0, 1339)\t1\n",
            "  (0, 1585)\t2\n",
            "  (0, 1624)\t1\n",
            "  (0, 1679)\t3\n",
            "  (0, 1726)\t1\n",
            "  (0, 1782)\t4\n",
            "  (0, 1843)\t1\n",
            "  :\t:\n",
            "  (0, 9000)\t1\n",
            "  (0, 9028)\t1\n",
            "  (0, 9135)\t1\n",
            "  (0, 9292)\t1\n",
            "  (0, 9300)\t1\n",
            "  (0, 9301)\t1\n",
            "  (0, 9394)\t1\n",
            "  (0, 9409)\t2\n",
            "  (0, 9473)\t1\n",
            "  (0, 9492)\t1\n",
            "  (0, 9494)\t1\n",
            "  (0, 9495)\t1\n",
            "  (0, 9631)\t1\n",
            "  (0, 9693)\t1\n",
            "  (0, 9695)\t1\n",
            "  (0, 9783)\t1\n",
            "  (0, 9993)\t1\n",
            "  (0, 10044)\t1\n",
            "  (0, 10066)\t3\n",
            "  (0, 10154)\t1\n",
            "  (0, 10197)\t1\n",
            "  (0, 10199)\t3\n",
            "  (0, 10205)\t3\n",
            "  (0, 10265)\t1\n",
            "  (0, 10272)\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6C5jGA_lEId",
        "colab_type": "text"
      },
      "source": [
        "## TF-IDF Vectors as features\n",
        "TF-IDF score represents the relative importance of a term in the document and the entire corpus. TF-IDF score is composed by two terms: the first computes the normalized Term Frequency (TF), the second term is the Inverse Document Frequency (IDF), computed as the logarithm of the number of the documents in the corpus divided by the number of documents where the specific term appears.\n",
        "\n",
        "$TF(t) = \\frac{\\text{Number of times term t appears in a document}}{\\text{Total number of terms in the document}}$\n",
        "\n",
        "$IDF(t) = log_e \\frac{\\text{Total number of documents}}{\\text{Number of documents with term t in it}}$\n",
        "\n",
        "TF-IDF Vectors can be generated at different levels of input tokens (words, characters, n-grams)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QPfPKAkm89N",
        "colab_type": "text"
      },
      "source": [
        "### **Word Level TF-IDF**\n",
        "Matrix representing tf-idf scores of every term in different documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61Rh6d8Nk_Ua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e1efbe2a-8bad-4a0b-9720-589d696275c2"
      },
      "source": [
        "# word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', \n",
        "                             token_pattern=r'\\w{1,}', \n",
        "                             max_features=5000)\n",
        "tfidf_vect.fit(X_train)\n",
        "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
        "xvalid_tfidf =  tfidf_vect.transform(X_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DD7Uje_IZoC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d6ec1e4-f4c9-4c92-9829-751274b652e2"
      },
      "source": [
        "xtrain_tfidf.shape  # (train examples, embedding size)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(442, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gMXafo8nZ6k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "outputId": "e3bfe07d-0568-446a-caa2-482a48a6e49f"
      },
      "source": [
        "print(xtrain_tfidf[0])  # (sentence index, word mapping)  tf-idf value"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "  (0, 4974)\t0.03743202251156108\n",
            "  (0, 4969)\t0.01808022692555903\n",
            "  (0, 4939)\t0.06116323801159181\n",
            "  (0, 4937)\t0.12954003075667303\n",
            "  (0, 4936)\t0.04132066398469017\n",
            "  (0, 4912)\t0.04676823074817047\n",
            "  (0, 4862)\t0.06728507548703201\n",
            "  (0, 4851)\t0.05109220774524617\n",
            "  (0, 4825)\t0.044247324218171624\n",
            "  (0, 4742)\t0.04607997650571246\n",
            "  (0, 4716)\t0.05653977450872648\n",
            "  (0, 4715)\t0.04370032024520131\n",
            "  (0, 4698)\t0.050075797166826905\n",
            "  (0, 4630)\t0.03505236625104993\n",
            "  (0, 4629)\t0.05221579751165078\n",
            "  (0, 4620)\t0.04268390966678205\n",
            "  (0, 4584)\t0.04865848062998934\n",
            "  (0, 4578)\t0.031634777226329944\n",
            "  (0, 4538)\t0.04914788700868163\n",
            "  (0, 4537)\t0.0422098654272356\n",
            "  (0, 4531)\t0.02591549539651008\n",
            "  (0, 4463)\t0.04132066398469017\n",
            "  (0, 4419)\t0.03505236625104993\n",
            "  (0, 4406)\t0.03234599001250806\n",
            "  (0, 4357)\t0.05109220774524617\n",
            "  :\t:\n",
            "  (0, 899)\t0.026752335492753024\n",
            "  (0, 880)\t0.0959518221119433\n",
            "  (0, 846)\t0.0390266647263748\n",
            "  (0, 826)\t0.1252679985259103\n",
            "  (0, 801)\t0.05653977450872648\n",
            "  (0, 781)\t0.06544042449842064\n",
            "  (0, 645)\t0.04132066398469017\n",
            "  (0, 616)\t0.035537187893675486\n",
            "  (0, 476)\t0.04370032024520131\n",
            "  (0, 458)\t0.050075797166826905\n",
            "  (0, 446)\t0.03458863060528745\n",
            "  (0, 409)\t0.05920959897513924\n",
            "  (0, 389)\t0.05848409524529102\n",
            "  (0, 350)\t0.0392720501389098\n",
            "  (0, 318)\t0.06506291944210214\n",
            "  (0, 291)\t0.08636002050444867\n",
            "  (0, 290)\t0.044247324218171624\n",
            "  (0, 249)\t0.06393166200877133\n",
            "  (0, 247)\t0.03773244348874402\n",
            "  (0, 151)\t0.031634777226329944\n",
            "  (0, 143)\t0.04914788700868163\n",
            "  (0, 107)\t0.030494000930115048\n",
            "  (0, 87)\t0.05109220774524617\n",
            "  (0, 85)\t0.06086375150580217\n",
            "  (0, 15)\t0.10443159502330156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLVRP3FAnEEy",
        "colab_type": "text"
      },
      "source": [
        "### **N-gram Level TF-IDF**\n",
        "N-grams are the combination of N terms together. This Matrix representing tf-idf scores of N-grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7DFEYzrnEzz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "304fb997-5d35-42f6-abca-32dc2e13b970"
      },
      "source": [
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', \n",
        "                                   token_pattern=r'\\w{1,}', \n",
        "                                   ngram_range=(2,4), # check for 2, 3, 4 grams\n",
        "                                   max_features=5000)\n",
        "tfidf_vect_ngram.fit(X_train)\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(X_train)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(X_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-ruQM78oFwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d4882179-c68b-490d-e08d-7bd4572c5003"
      },
      "source": [
        "xtrain_tfidf_ngram"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<442x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 18055 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdtX0CUhnLM4",
        "colab_type": "text"
      },
      "source": [
        "### **Character Level TF-IDF**\n",
        "Matrix representing tf-idf scores of character level n-grams in the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zFk52hUnQi5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c4f7153b-4e4d-4c35-f235-92fe8999f2b5"
      },
      "source": [
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', \n",
        "                                         ngram_range=(2,4), \n",
        "                                         max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(X_train)\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(X_train) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(X_test) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GJkKVDtoVqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "976a6793-0635-42a3-90dc-b303c3ffe117"
      },
      "source": [
        "xtrain_tfidf_ngram_chars"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<442x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 594844 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7flQDxzqVVh",
        "colab_type": "text"
      },
      "source": [
        "## Word Embeddings\n",
        "A word embedding is a form of representing words and documents using a dense vector representation. The position of a word within the vector space is learned from text and is based on the words that surround the word when it is used. Word embeddings can be trained using the input corpus itself or can be generated using pre-trained word embeddings such as Glove, FastText, and Word2Vec. Any one of them can be downloaded and used as transfer learning. I'll be using GloVe.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1K0Wirtobdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "4815b905-508d-4e03-bbf8-1ad302224651"
      },
      "source": [
        "# download GloVe Embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "--2020-08-19 12:55:17--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-08-19 12:55:17--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-08-19 12:55:18--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: glove.6B.zip.1\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  2.07MB/s    in 6m 27s  \n",
            "\n",
            "2020-08-19 13:01:45 (2.12 MB/s) - glove.6B.zip.1 saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dp0Q311q418",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ab349ed4-5076-4638-d68e-efb9046471c1"
      },
      "source": [
        "# unzip Embedding file\n",
        "import zipfile\n",
        "with zipfile.ZipFile(r\"./glove.6B.zip\", 'r') as f:\n",
        "    f.extractall(r\"./GloVe\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcKGyPJdtDWV",
        "colab_type": "text"
      },
      "source": [
        "Following snnipet shows how to use pre-trained word embeddings in the model. There are four essential steps:\n",
        "\n",
        "1. Loading the pretrained word embeddings\n",
        "2. Creating a tokenizer object\n",
        "3. Transforming text documents to sequence of tokens and pad them\n",
        "4. Create a mapping of token and their respective embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7CW5ql1uOxT",
        "colab_type": "text"
      },
      "source": [
        "### Loading the pretrained word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtNLz4k6spcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e29d1d6a-42c0-470c-9913-d1ba31410055"
      },
      "source": [
        "# load the pre-trained word-embedding vectors \n",
        "embeddings_index = {}\n",
        "for i, line in enumerate(open('./GloVe/glove.6B.300d.txt')):\n",
        "    values = line.split()\n",
        "    embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIPt1PKbt7QH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb5ecd01-496a-45e5-b778-a32dcd6dc417"
      },
      "source": [
        "embeddings_index[\"the\"].shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPcmuKLquRBe",
        "colab_type": "text"
      },
      "source": [
        "### Create a tokenizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x35XO2UtWS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "facffb0d-afc6-497a-961c-473b941b45e7"
      },
      "source": [
        "# create a tokenizer \n",
        "token = text.Tokenizer()\n",
        "token.fit_on_texts(X_train)\n",
        "word_index = token.word_index"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDOgasZau6Fh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5f70cf41-2546-43d3-a5ea-e84ee05b19e7"
      },
      "source": [
        "print(word_index[\"makes\"])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aOvaioIueo4",
        "colab_type": "text"
      },
      "source": [
        "### Transforming text documents to sequence of tokens and pad them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMy4tk_Gvu4y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6466a53-74b0-4597-8e24-105ab0263e60"
      },
      "source": [
        "# check min length of text in train Dataset\n",
        "X_train.str.len().min()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "439"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwO1JfJktduD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6be6d5b5-b883-4bac-b362-542f8c5c44d5"
      },
      "source": [
        "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
        "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(X_train), maxlen=200)\n",
        "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(X_test), maxlen=200)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQf5ja8VwKTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dda3f75d-b85d-4be0-f073-8c021d838b81"
      },
      "source": [
        "train_seq_x.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(442, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHLdNJYGvjKY",
        "colab_type": "text"
      },
      "source": [
        "### Create a mapping of token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85nrXJrkth2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0cf342d4-7ce6-45e1-b028-5e1d86c57458"
      },
      "source": [
        "# create token-embedding mapping\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpnD2sJbwesv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24f2f391-2dbb-46a9-ae35-16ae38cc4f35"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10334, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59TCy4nmtdFo",
        "colab_type": "text"
      },
      "source": [
        "## Text / NLP based features\n",
        "A number of extra text based features can also be created which sometimes are helpful for improving text classification models. Some examples are:\n",
        "\n",
        "1. Word Count of the documents  total number of words in the documents\n",
        "2. Character Count of the documents  total number of characters in the documents\n",
        "3. Average Word Density of the documents  average length of the words used in the documents\n",
        "4. Puncutation Count in the Complete Essay  total number of punctuation marks in the documents\n",
        "5. Upper Case Count in the Complete Essay  total number of upper count words in the documents\n",
        "6. Title Word Count in the Complete Essay  total number of proper case (title) words in the documents\n",
        "7. Frequency distribution of Part of Speech Tags:\n",
        "\t* Noun Count\n",
        "\t* Verb Count\n",
        "\t* Adjective Count\n",
        "\t* Adverb Count\n",
        "\t* Pronoun Count\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm0Jw1tA0OWu",
        "colab_type": "text"
      },
      "source": [
        "### Textual Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exnpr_DYyPDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7b8071e6-5fb6-41e2-bdf8-5ac3c915bdc1"
      },
      "source": [
        "train_df = pd.DataFrame({\n",
        "    \"text\" : X_train,\n",
        "    \"label\": y_train\n",
        "})\n",
        "train_df.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>pittman drops coach uk base australia world 40...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>england attempt create history first test port...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>pavey focuses indoor success jo pavey miss jan...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>benitez delight crucial win liverpool manager ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>666</th>\n",
              "      <td>hewitt overcomes wobble sydney lleyton hewitt ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  label\n",
              "96   pittman drops coach uk base australia world 40...      0\n",
              "171  england attempt create history first test port...      1\n",
              "73   pavey focuses indoor success jo pavey miss jan...      0\n",
              "353  benitez delight crucial win liverpool manager ...      2\n",
              "666  hewitt overcomes wobble sydney lleyton hewitt ...      4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVdH1Jk6zEke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1e22ecad-3b7d-4483-eba0-8b14878f96a4"
      },
      "source": [
        "train_df['char_count'] = train_df['text'].apply(len)\n",
        "\n",
        "train_df['word_count'] = train_df['text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "train_df['word_density'] = train_df['char_count'] / (train_df['word_count']+1)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ9--ygrzy9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0737e75a-070b-4c07-cf7c-0cf6b92b1e01"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>pittman drops coach uk base australia world 40...</td>\n",
              "      <td>0</td>\n",
              "      <td>1451</td>\n",
              "      <td>201</td>\n",
              "      <td>7.183168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>england attempt create history first test port...</td>\n",
              "      <td>1</td>\n",
              "      <td>2080</td>\n",
              "      <td>312</td>\n",
              "      <td>6.645367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>pavey focuses indoor success jo pavey miss jan...</td>\n",
              "      <td>0</td>\n",
              "      <td>561</td>\n",
              "      <td>81</td>\n",
              "      <td>6.841463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>benitez delight crucial win liverpool manager ...</td>\n",
              "      <td>2</td>\n",
              "      <td>1269</td>\n",
              "      <td>190</td>\n",
              "      <td>6.643979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>666</th>\n",
              "      <td>hewitt overcomes wobble sydney lleyton hewitt ...</td>\n",
              "      <td>4</td>\n",
              "      <td>1076</td>\n",
              "      <td>163</td>\n",
              "      <td>6.560976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  ...  word_density\n",
              "96   pittman drops coach uk base australia world 40...  ...      7.183168\n",
              "171  england attempt create history first test port...  ...      6.645367\n",
              "73   pavey focuses indoor success jo pavey miss jan...  ...      6.841463\n",
              "353  benitez delight crucial win liverpool manager ...  ...      6.643979\n",
              "666  hewitt overcomes wobble sydney lleyton hewitt ...  ...      6.560976\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZFDmJZR0RMI",
        "colab_type": "text"
      },
      "source": [
        "### POS Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_s9UpJ3z9Gr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ec85f876-fd96-4da8-ebf6-4ed0ebe77317"
      },
      "source": [
        "pos_family = {\n",
        "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
        "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
        "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
        "    'adj' :  ['JJ','JJR','JJS'],\n",
        "    'adv' : ['RB','RBR','RBS','WRB']\n",
        "}\n",
        "\n",
        "# function to check and get the part of speech tag count of a words in a given sentence\n",
        "def check_pos_tag(x, flag):\n",
        "    cnt = 0\n",
        "    try:\n",
        "        wiki = textblob.TextBlob(x)\n",
        "        for tup in wiki.tags:\n",
        "            ppo = list(tup)[1]\n",
        "            if ppo in pos_family[flag]:\n",
        "                cnt += 1\n",
        "    except:\n",
        "        pass\n",
        "    return cnt"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lmbz65w0gqJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "af871ec2-b504-4c4d-8fe0-f2d67d3a24ef"
      },
      "source": [
        "train_df['noun_count'] = train_df['text'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
        "train_df['verb_count'] = train_df['text'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
        "train_df['adj_count'] = train_df['text'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
        "train_df['adv_count'] = train_df['text'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
        "train_df['pron_count'] = train_df['text'].apply(lambda x: check_pos_tag(x, 'pron'))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W9WXwz70qG0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b727fb1d-48fb-48b6-ec54-441c24939115"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>word_density</th>\n",
              "      <th>noun_count</th>\n",
              "      <th>verb_count</th>\n",
              "      <th>adj_count</th>\n",
              "      <th>adv_count</th>\n",
              "      <th>pron_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>pittman drops coach uk base australia world 40...</td>\n",
              "      <td>0</td>\n",
              "      <td>1451</td>\n",
              "      <td>201</td>\n",
              "      <td>7.183168</td>\n",
              "      <td>89</td>\n",
              "      <td>47</td>\n",
              "      <td>41</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>england attempt create history first test port...</td>\n",
              "      <td>1</td>\n",
              "      <td>2080</td>\n",
              "      <td>312</td>\n",
              "      <td>6.645367</td>\n",
              "      <td>160</td>\n",
              "      <td>61</td>\n",
              "      <td>47</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>pavey focuses indoor success jo pavey miss jan...</td>\n",
              "      <td>0</td>\n",
              "      <td>561</td>\n",
              "      <td>81</td>\n",
              "      <td>6.841463</td>\n",
              "      <td>43</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>benitez delight crucial win liverpool manager ...</td>\n",
              "      <td>2</td>\n",
              "      <td>1269</td>\n",
              "      <td>190</td>\n",
              "      <td>6.643979</td>\n",
              "      <td>80</td>\n",
              "      <td>46</td>\n",
              "      <td>43</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>666</th>\n",
              "      <td>hewitt overcomes wobble sydney lleyton hewitt ...</td>\n",
              "      <td>4</td>\n",
              "      <td>1076</td>\n",
              "      <td>163</td>\n",
              "      <td>6.560976</td>\n",
              "      <td>63</td>\n",
              "      <td>34</td>\n",
              "      <td>40</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  ...  pron_count\n",
              "96   pittman drops coach uk base australia world 40...  ...           0\n",
              "171  england attempt create history first test port...  ...           0\n",
              "73   pavey focuses indoor success jo pavey miss jan...  ...           0\n",
              "353  benitez delight crucial win liverpool manager ...  ...           3\n",
              "666  hewitt overcomes wobble sydney lleyton hewitt ...  ...           0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kfwgphcp15uB",
        "colab_type": "text"
      },
      "source": [
        "## Topic Modelling as Features\n",
        "Topic Modelling is a technique to identify the groups of words (called a topic) from a collection of documents that contains best information in the collection. I have used Latent Dirichlet Allocation for generating Topic Modelling Features. LDA is an iterative model which starts from a fixed number of topics. Each topic is represented as a distribution over words, and each document is then represented as a distribution over topics. Although the tokens themselves are meaningless, the probability distributions over words provided by the topics provide a sense of the different ideas contained in the documents. One can read more about topic modelling [here](https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3ewyN-y0smT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d5f9838c-b35c-4df7-e03f-bbb4c0bf46e3"
      },
      "source": [
        "# train a LDA Model\n",
        "lda_model = decomposition.LatentDirichletAllocation(n_components=20, \n",
        "                                                    learning_method='online', \n",
        "                                                    max_iter=20)\n",
        "X_topics = lda_model.fit_transform(xtrain_count)\n",
        "topic_word = lda_model.components_ \n",
        "vocab = count_vect.get_feature_names()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN-Pn4ammEpH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "873bb505-574f-40d6-d7a1-39e134937e63"
      },
      "source": [
        "# view the topic models\n",
        "n_top_words = 10\n",
        "topic_summaries = []\n",
        "for i, topic_dist in enumerate(topic_word):\n",
        "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
        "    topic_summaries.append(' '.join(topic_words))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkDzD1RT3mqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "36d07c27-ffd9-41dd-92c9-c5a4fc3a780a"
      },
      "source": [
        "print(topic_word)\n",
        "print(f\"topic_summaries - {topic_summaries}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[ 0.0535939   0.05152525  0.0515803  ...  0.05116905  0.05152836\n",
            "   0.05178971]\n",
            " [17.82846309  0.05142333  0.93115276 ...  0.05169041  0.0515823\n",
            "   0.05159669]\n",
            " [ 0.05149415  0.05157861  0.05152254 ...  0.0515337   0.05156218\n",
            "   0.05158628]\n",
            " ...\n",
            " [ 0.05199928  0.0516737   0.051455   ...  0.05139539  0.05143658\n",
            "   0.05159432]\n",
            " [ 1.99244952  0.05187039  0.05133226 ...  0.05188035  0.0517084\n",
            "   0.05163511]\n",
            " [ 0.05161962  0.05163108  0.05152399 ...  0.05171195  0.05172995\n",
            "   0.05134608]]\n",
            "topic_summaries - ['win great team country first last cross pavey indoor england', 'england mark first european best strauss jones indoor south one', 'high breaks knowledge moggi crease andrew weigh endorse slipped england', 'said football england would association mutu chelsea sponsorship fai rooney', 'one four said first cup final leg two ntini strauss', 'liverpool win would play said parry first final one back', 'cricket sri day lanka tour zimbabwe played one also jayasuriya', 'cup year said would davis england time henman world last', 'fai rochus sponsorship delaney saracens friday coria mcmullen raiwalui headingley', 'said england year world first one game team last players', 'thanou greek kenteris iaaf athens tests drugs missing charges appeal', 'said would club chelsea players league football arsenal manager liverpool', 'got said chelsea give points like team seven arsenal wenger', 'doping drugs conte said jones anti iaaf us balco ban', 'blackburn prinz home round burnley injury time robben last cup', 'half england game side first wales minutes goal ireland back', 'gerrard liverpool said would want club england benitez anfield year', 'pakistan india australia test khan wicket mohammad day first ul', 'radcliffe v marathon race cross paula republic chepkemei ireland york', 'mutu division juventus totesport moggi bucharest banned placed resisted relegation']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_PEqfOC4i3V",
        "colab_type": "text"
      },
      "source": [
        "# Model Building\n",
        "The final step in the text classification framework is to train a classifier using the features created in the previous step. There are many different choices of machine learning models which can be used to train a final model. We will implement following different classifiers for this purpose:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIb6AA5Jph6N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7906040d-9c44-4db7-80d5-8c0f1a822472"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    \n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return metrics.accuracy_score(predictions, valid_y)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd1A3zxOo5T2",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes Classifier\n",
        "\n",
        "Naive Bayes is a classification technique based on Bayes Theorem with an assumption of independence among predictors. A Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlty9MBBpNMO",
        "colab_type": "text"
      },
      "source": [
        "### NB on Count Vectors (One hot)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5twWZLApQeh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "f7173137-c9e7-43fc-d3e7-ae72a650d247"
      },
      "source": [
        "# create NB Classifier\n",
        "NB_count_vec = naive_bayes.MultinomialNB()\n",
        "\n",
        "# train NB\n",
        "NB_count_vec.fit(xtrain_count, y_train)\n",
        "\n",
        "# get predictions\n",
        "preds = NB_count_vec.predict(xvalid_count)\n",
        "\n",
        "# accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"NB, Count Vectors: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "NB, Count Vectors:  1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        40\n",
            "           1       1.00      1.00      1.00        50\n",
            "           2       1.00      1.00      1.00       106\n",
            "           3       1.00      1.00      1.00        59\n",
            "           4       1.00      1.00      1.00        40\n",
            "\n",
            "    accuracy                           1.00       295\n",
            "   macro avg       1.00      1.00      1.00       295\n",
            "weighted avg       1.00      1.00      1.00       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z4P6rogg8Ba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17887bcb-733a-4c51-89ce-de57d90d64c5"
      },
      "source": [
        "# select some random examples from test set and check their labels\n",
        "random.seed(47)  # for reproducible results\n",
        "examples_index = random.choices(range(X_test.shape[0]), k=5)  # of shuffled data\n",
        "examples_index_orig = X_test.iloc[examples_index].reset_index()[\"index\"] # of original data\n",
        "# print(examples_index, examples_index_orig)\n",
        "\n",
        "temp_df = raw_df.iloc[X_test.iloc[examples_index].reset_index()[\"index\"]].copy()\n",
        "temp_df[\"Predicted\"] = label_encoder.inverse_transform(preds[examples_index])\n",
        "\n",
        "for idx, description, actual_lbl, predicted_lbl in temp_df.itertuples():\n",
        "    print(f\"\\nDescription:\\n\", description.replace('\\n', ' '))\n",
        "    print(f\"Actual Label - {actual_lbl}\\t\\tPredicted - {predicted_lbl}\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Description:\n",
            " Benitez deflects blame from Dudek  Liverpool manager Rafael Benitez has refused to point the finger of blame at goalkeeper Jerzy Dudek after Portsmouth claimed a draw at Anfield.  Dudek fumbled a cross before Lomana LuaLua headed home an injury-time equaliser, levelling after Steven Gerrard put Liverpool ahead. Benitez said: \"It was difficult for Jerzy. It was an unlucky moment. \"He was expecting a cross from Matthew Taylor and it ended up like a shot, so I don't blame him for what happened.\" Benitez admitted it was a costly loss of two points by Liverpool, who followed up their derby defeat against Everton with a disappointing draw. He said: \"We had many opportunities but didn't score and, in the end, a 1-0 lead was not enough. \"If you don't have any chances you have to think of other things, but when you are creating so many chances as we are there is nothing you can say to the players. It was a pity. \"We lost two points, but we have one more point in the table. Now we have another difficult game against Newcastle and we have to recover quickly from that.\" \n",
            "Actual Label - football\t\tPredicted - football\n",
            "\n",
            "Description:\n",
            " Ferguson urges Henry punishment  Sir Alex Ferguson has called on the Football Association to punish Arsenal's Thierry Henry for an incident involving Gabriel Heinze.  Ferguson believes Henry deliberately caught Heinze on the head with his knee during United's controversial win. The United boss said it was worse than Ruud van Nistelrooy's foul on Ashley Cole for which he got a three-game ban. \"We shall present it to the FA and see what they do. The tackle on Heinze was terrible,\" he said. Clubs are permitted to ask the FA to examine specific incidents but information is expected to be provided within 48 hours of the game. The clash occurred moments before half-time when a Freddie Ljungberg challenge left Heinze on the ground on the left touchline. Henry, following the ball, attempted to hurdle the Argentine but his knee collided with the back of Heinze's head.  The striker protested his innocence - and referee Mike Riley deemed the collision accidental. Ferguson was also upset by Arsenal's overall discipline during the heated encounter between the two arch-rivals and praised his own side's behaviour. \"Edu produced a terrible tackle on Scholes that was a potential leg-breaker,\" he said. \"There were 24 fouls in the game by Arsenal, seven on Heinze, five on Ronaldo, six by Vieira - and it was only his sixth foul that got him booked. Phil Neville got booked for his first challenge. \"I am proud of my players for the way they handled that pressure. \"We have always been good at being gracious in defeat. What happened on Sunday overshadowed our achievement, but then they do it all the time, don't they?\" \n",
            "Actual Label - football\t\tPredicted - football\n",
            "\n",
            "Description:\n",
            " Premier League probes Cole claims  The Premier League is to investigate allegations that Chelsea made an illegal approach for Ashley Cole.  Arsenal and England defender Cole reportedly met Blues boss Jose Mourinho and chief executive Peter Kenyon in a London hotel 10 days ago. Chelsea have yet to officially confirm or deny the meeting, which would be in breach of Premier League rule K3. Now the Gunners have asked for an inquiry to look into claims that their player has been \"tapped up\". The Premier League says it will look into \"further information\" concerning the allegations, which it received from the News of the World on Saturday. Both clubs have pledged to co-operate with the inquiry.  A statement from Chelsea read: \"Chelsea can confirm it has been in discussions with the Premier League over the last few days and we will be co-operating fully with the inquiry announced today. \"It would be inappropiate to make any further comment until the inquiry is completed.\" The Premier League's statement confirmed Arsenal had asked for the matter to be investigated. It read: \"The board is finally able to establish a clear position from Arsenal and is grateful for chairman Peter Hill-Wood's confirmation that his club want the Premier League to investigate the matter and that they will co-operate fully with any inquiry. \"The board is also pleased that Chelsea have given a similar undertaking.\" Gunners vice-chairman David Dein has voiced concern at Chelsea's stance on the issue, and told the News of the World: \"From the evidence I have seen so far there is a huge credibility gap.\"  If Chelsea are found guilty of an illegal approach, they could be deducted points - although Arsenal boss Arsene Wenger has said he would be opposed to this. Aston Villa were recently given a reprimand by the Premier League after Southampton complained about an approach to James Beattie earlier in the season. Chelsea boss Jose Mourinho, speaking after his side's draw with Manchester City on Sunday, insisted he is not worried about the inquiry or its outcome. \"To me, the effect is zero,\" he said. \"I know nothing about it and I don't want to know about it. I'm not worried about it. My life is the same, trying to enjoy my work and my life.\" Meanwhile, Everton boss David Moyes told BBC Radio Five Live that stopping clubs from approaching players via their agents would be difficult. \"It's part of football and will be very hard to change. It does happen a lot,\" he told BBC Radio Five Live's Sportsweek programme. \"It should be manager to manager or chairman to chairman but the way modern football has gone I don't think that happens. \"There is a way the player gets got to but that is part of football. I don't think it is right but that is the way it works.\" \n",
            "Actual Label - football\t\tPredicted - football\n",
            "\n",
            "Description:\n",
            " Mauresmo opens with victory in LA  Amelie Mauresmo and Maria Sharapova won their opening matches at the Tour Championships in Los Angeles.  France's Mauresmo routed Vera Zvonareva 6-1 6-0, while Wimbledon champion Sharapova was a 6-1 6-4 winner over fellow Russian Svetlana Kuznetsova. American Serena Williams also won, edging Russian Elena Dementieva 7-6 7-5 for her second victory of the event. The event is split into two groups of four with the top two from each advancing to the semi-finals.  Mauresmo's win was her ninth in a row as she tries to overtake Lindsay Davenport for the number one spot. Mauresmo spent five weeks at number one after the US Open before injury ushered Davenport back in front. \"Since then, I feel very confident on court and my game is there. I want to get the ranking back, but it's very different than before I was number one. \"It was an obsession, but now I take it in a relaxed way.\" Mauresmo completed her first match in the season-ending championship in 54 minutes as Russia's Zvonareva struggled to return her serve and failed to achieve a single break point.  \"She got mad a little bit and I played some great tennis,\" said Mauresmo, who was runner-up to Kim Clijsters in last year's final. Zvonareva has lost both her games so far, having crashed 6-2 6-4 Kuznetsova in the Staples Centre on Wednesday. \"Sometimes not everything works,\" she said. \"It was lots of pressure. Maybe that is why I couldn't do 100%. But I was fighting.\" Sharapova, who lost 6-2 6-2 to Kuznetsova in Beijing in September, said: \"In Beijing, she was coming off such a big winning streak [14 matches] and she was unstoppable. \"This time, it was important to start off well and put some pressure on her.\" The tournament debutant added: \"I love it here. The atmosphere is great. \"To be here where the Lakers play, you just feel that excitement. I love basketball.\" Williams admitted she is still some way off her best form but remained positive after two wins in two days. \"It's hard to go out there and get it right but I'm fighting and I'm hoping,\" said Williams. \"What makes me happy is the effort. I had a really good effort today. \"I'm trying to add new dimensions to my game.\" \n",
            "Actual Label - tennis\t\tPredicted - tennis\n",
            "\n",
            "Description:\n",
            " Verdict delay for Greek sprinters  Greek athletics' governing body has postponed by two weeks the judgement on sprinters Costas Kenteris and Katerina Thanou for missing doping tests.  The pair are facing lengthy bans for the missed tests, including one on the eve of last year's Athens Olympics. They were set to learn their fate by the end of February, but late evidence from them has pushed the date back. \"A decision is now expected by around mid-March,\" said one of their lawyers, Michalis Dimitrakopoulos. Kenteris, 31, who won the men's 200m title at the 2000 Sydney Games and Thanou, 30, who won the women's 100m silver medal in Sydney, face a maximum two-year ban if found guilty. The athletes, who spectacularly withdrew from the Athens Olympics, have been suspended by the International Association of Athletics Federations (IAAF) for missing the three tests. The IAAF said the sprinters had failed to provide samples for tests in Tel Aviv, Chicago and Athens and ordered Greek athletic's governing body, Segas, to hold a disciplinary inquiry. The athletes also face a criminal hearing in Greece over the missed drugs tests and have been charged with faking a motorcycle accident on the day of the Athens test, which led to them spending four days in hospital. Following the final hearing in late January, the athletes sounded confident they would be acquitted. \"I am confident and optimistic,\" Thanou had said at the time. \"We presented new evidence to the committee that they were not aware of.\" It was not clear what this new evidence was. \n",
            "Actual Label - athletics\t\tPredicted - athletics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhKpoF7_s8SM",
        "colab_type": "text"
      },
      "source": [
        "### NB on TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSQ3zaYzs0d2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "a983bb06-8694-4695-a81a-b7c6edaed685"
      },
      "source": [
        "# create NB Classifier\n",
        "NB_tf_idf = naive_bayes.MultinomialNB()\n",
        "\n",
        "# train NB\n",
        "NB_tf_idf.fit(xtrain_tfidf, y_train)\n",
        "\n",
        "# get predictions\n",
        "preds = NB_tf_idf.predict(xvalid_tfidf)\n",
        "\n",
        "# accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"NB, WordLevel TF-IDF: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "NB, WordLevel TF-IDF:  0.9559322033898305\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96        40\n",
            "           1       1.00      1.00      1.00        50\n",
            "           2       0.89      1.00      0.94       106\n",
            "           3       1.00      0.88      0.94        59\n",
            "           4       1.00      0.93      0.96        40\n",
            "\n",
            "    accuracy                           0.96       295\n",
            "   macro avg       0.98      0.95      0.96       295\n",
            "weighted avg       0.96      0.96      0.96       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vR7DgxGtGtw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "950deb62-c185-4dfd-df71-c39661b67038"
      },
      "source": [
        "# select some random examples from test set and check their labels\n",
        "random.seed(47)  # for reproducible results\n",
        "examples_index = random.choices(range(X_test.shape[0]), k=15)  # of shuffled data\n",
        "examples_index_orig = X_test.iloc[examples_index].reset_index()[\"index\"] # of original data\n",
        "# print(examples_index, examples_index_orig)\n",
        "\n",
        "temp_df = raw_df.iloc[X_test.iloc[examples_index].reset_index()[\"index\"]].copy()\n",
        "temp_df[\"Predicted\"] = label_encoder.inverse_transform(preds[examples_index])\n",
        "\n",
        "for idx, description, actual_lbl, predicted_lbl in temp_df.itertuples():\n",
        "    # print(f\"\\nDescription:\\n\", description.replace('\\n', ' '))\n",
        "    print(f\"Actual Label - {actual_lbl}\\t\\tPredicted - {predicted_lbl}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - tennis\t\tPredicted - tennis\n",
            "Actual Label - athletics\t\tPredicted - athletics\n",
            "Actual Label - athletics\t\tPredicted - athletics\n",
            "Actual Label - athletics\t\tPredicted - football\n",
            "Actual Label - athletics\t\tPredicted - athletics\n",
            "Actual Label - cricket\t\tPredicted - cricket\n",
            "Actual Label - rugby\t\tPredicted - football\n",
            "Actual Label - cricket\t\tPredicted - cricket\n",
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - rugby\t\tPredicted - rugby\n",
            "Actual Label - football\t\tPredicted - football\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB2rg8BqtTkS",
        "colab_type": "text"
      },
      "source": [
        "### NB on Ngram Level TF IDF Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK5aLv3otYty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "157f607e-1280-4917-d6ff-f1894e42c382"
      },
      "source": [
        "# create NB Classifier\n",
        "NB_ngram_tf_idf = naive_bayes.MultinomialNB()\n",
        "\n",
        "# train NB\n",
        "NB_ngram_tf_idf.fit(xtrain_tfidf_ngram, y_train)\n",
        "\n",
        "# get predictions\n",
        "preds = NB_ngram_tf_idf.predict(xvalid_tfidf_ngram)\n",
        "\n",
        "# accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"NB, N-Gram TF-IDF Vectors: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "NB, N-Gram TF-IDF Vectors:  0.9559322033898305\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.93        40\n",
            "           1       1.00      0.98      0.99        50\n",
            "           2       0.89      1.00      0.94       106\n",
            "           3       1.00      0.92      0.96        59\n",
            "           4       1.00      0.95      0.97        40\n",
            "\n",
            "    accuracy                           0.96       295\n",
            "   macro avg       0.98      0.94      0.96       295\n",
            "weighted avg       0.96      0.96      0.96       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVXT8qP6th1N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "db0341fb-ff08-41cf-8602-4e26d9e28172"
      },
      "source": [
        "# select some random examples from test set and check their labels\n",
        "random.seed(47)  # for reproducible results\n",
        "examples_index = random.choices(range(X_test.shape[0]), k=15)  # of shuffled data\n",
        "examples_index_orig = X_test.iloc[examples_index].reset_index()[\"index\"] # of original data\n",
        "# print(examples_index, examples_index_orig)\n",
        "\n",
        "temp_df = raw_df.iloc[X_test.iloc[examples_index].reset_index()[\"index\"]].copy()\n",
        "temp_df[\"Predicted\"] = label_encoder.inverse_transform(preds[examples_index])\n",
        "\n",
        "for idx, description, actual_lbl, predicted_lbl in temp_df.itertuples():\n",
        "    # print(f\"\\nDescription:\\n\", description.replace('\\n', ' '))\n",
        "    print(f\"Actual Label - {actual_lbl}\\t\\tPredicted - {predicted_lbl}\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - tennis\t\tPredicted - tennis\n",
            "Actual Label - athletics\t\tPredicted - athletics\n",
            "Actual Label - athletics\t\tPredicted - athletics\n",
            "Actual Label - athletics\t\tPredicted - football\n",
            "Actual Label - athletics\t\tPredicted - athletics\n",
            "Actual Label - cricket\t\tPredicted - cricket\n",
            "Actual Label - rugby\t\tPredicted - rugby\n",
            "Actual Label - cricket\t\tPredicted - cricket\n",
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - rugby\t\tPredicted - rugby\n",
            "Actual Label - football\t\tPredicted - football\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqRGACqdtr6u",
        "colab_type": "text"
      },
      "source": [
        "### NB on Character Level TF IDF Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8XGPGSlto2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "efcb47a3-b808-4f11-cfc4-bb5426a63439"
      },
      "source": [
        "# create NB Classifier\n",
        "NB_chars_tf_idf = naive_bayes.MultinomialNB()\n",
        "\n",
        "# train NB\n",
        "NB_chars_tf_idf.fit(xtrain_tfidf_ngram_chars, y_train)\n",
        "\n",
        "# get predictions\n",
        "preds = NB_chars_tf_idf.predict(xvalid_tfidf_ngram_chars)\n",
        "\n",
        "# accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"NB, CharLevel TF-IDF Vectors: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "NB, CharLevel TF-IDF Vectors:  0.7152542372881356\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.68      0.81        40\n",
            "           1       1.00      0.74      0.85        50\n",
            "           2       0.56      1.00      0.72       106\n",
            "           3       0.97      0.63      0.76        59\n",
            "           4       1.00      0.10      0.18        40\n",
            "\n",
            "    accuracy                           0.72       295\n",
            "   macro avg       0.91      0.63      0.66       295\n",
            "weighted avg       0.84      0.72      0.69       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScoFS3xct5ev",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "72597845-20d8-45b9-ce4d-2c55c430653b"
      },
      "source": [
        "# select some random examples from test set and check their labels\n",
        "random.seed(47)  # for reproducible results\n",
        "examples_index = random.choices(range(X_test.shape[0]), k=15)  # of shuffled data\n",
        "examples_index_orig = X_test.iloc[examples_index].reset_index()[\"index\"] # of original data\n",
        "# print(examples_index, examples_index_orig)\n",
        "\n",
        "temp_df = raw_df.iloc[X_test.iloc[examples_index].reset_index()[\"index\"]].copy()\n",
        "temp_df[\"Predicted\"] = label_encoder.inverse_transform(preds[examples_index])\n",
        "\n",
        "for idx, description, actual_lbl, predicted_lbl in temp_df.itertuples():\n",
        "    # print(f\"\\nDescription:\\n\", description.replace('\\n', ' '))\n",
        "    print(f\"Actual Label - {actual_lbl}\\t\\tPredicted - {predicted_lbl}\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - tennis\t\tPredicted - football\n",
            "Actual Label - athletics\t\tPredicted - athletics\n",
            "Actual Label - athletics\t\tPredicted - football\n",
            "Actual Label - athletics\t\tPredicted - football\n",
            "Actual Label - athletics\t\tPredicted - football\n",
            "Actual Label - cricket\t\tPredicted - cricket\n",
            "Actual Label - rugby\t\tPredicted - football\n",
            "Actual Label - cricket\t\tPredicted - cricket\n",
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - football\t\tPredicted - football\n",
            "Actual Label - rugby\t\tPredicted - football\n",
            "Actual Label - football\t\tPredicted - football\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1gkh5mxxW2v",
        "colab_type": "text"
      },
      "source": [
        "## Linear Classifier\n",
        "Linear Classifier (Logistic Regression) measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic/sigmoid function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzHAp1ik1i2i",
        "colab_type": "text"
      },
      "source": [
        "### LR on Count Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwFXEx7qxWTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "447334fe-bc21-4773-f0ab-44b50d2035e2"
      },
      "source": [
        "# create LR Classifier\n",
        "LR_count_vec = linear_model.LogisticRegression()\n",
        "\n",
        "# train LR\n",
        "LR_count_vec.fit(xtrain_count, y_train)\n",
        "\n",
        "# get predictions\n",
        "preds = LR_count_vec.predict(xvalid_count)\n",
        "\n",
        "# accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"LR, Count Vectors: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR, Count Vectors:  0.9864406779661017\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        40\n",
            "           1       1.00      1.00      1.00        50\n",
            "           2       0.96      1.00      0.98       106\n",
            "           3       1.00      0.97      0.98        59\n",
            "           4       1.00      0.97      0.99        40\n",
            "\n",
            "    accuracy                           0.99       295\n",
            "   macro avg       0.99      0.98      0.99       295\n",
            "weighted avg       0.99      0.99      0.99       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsqSFJWw1DFS",
        "colab_type": "text"
      },
      "source": [
        "### LR on TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxSN7uMj0SlO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "73529c21-c2ae-40ec-9b07-bab7dcfddafc"
      },
      "source": [
        "# create LR Classifier\n",
        "LR_tf_idf = linear_model.LogisticRegression()\n",
        "\n",
        "# train LR\n",
        "LR_tf_idf.fit(xtrain_tfidf, y_train)\n",
        "\n",
        "# get predictions\n",
        "preds = LR_tf_idf.predict(xvalid_tfidf)\n",
        "\n",
        "# accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"LR, Word Level TF-IDF: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR, Word Level TF-IDF:  0.9796610169491525\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        40\n",
            "           1       1.00      1.00      1.00        50\n",
            "           2       0.95      1.00      0.97       106\n",
            "           3       1.00      0.93      0.96        59\n",
            "           4       1.00      0.97      0.99        40\n",
            "\n",
            "    accuracy                           0.98       295\n",
            "   macro avg       0.99      0.98      0.98       295\n",
            "weighted avg       0.98      0.98      0.98       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgPfQjHn08R5",
        "colab_type": "text"
      },
      "source": [
        "### LR on Ngram Level TF IDF Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQBsQyH00PmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "65602da0-27f3-4b08-9ecb-d6d757062e7d"
      },
      "source": [
        "# create LR Classifier\n",
        "LR_ngram_tf_idf = linear_model.LogisticRegression()\n",
        "\n",
        "# train LR\n",
        "LR_ngram_tf_idf.fit(xtrain_tfidf_ngram, y_train)\n",
        "\n",
        "# get predictions\n",
        "preds = LR_ngram_tf_idf.predict(xvalid_tfidf_ngram)\n",
        "\n",
        "# accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"LR, N-gram TF-IDF: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR, N-gram TF-IDF:  0.9423728813559322\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.85      0.92        40\n",
            "           1       1.00      0.96      0.98        50\n",
            "           2       0.86      1.00      0.93       106\n",
            "           3       1.00      0.90      0.95        59\n",
            "           4       1.00      0.93      0.96        40\n",
            "\n",
            "    accuracy                           0.94       295\n",
            "   macro avg       0.97      0.93      0.95       295\n",
            "weighted avg       0.95      0.94      0.94       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FS-Jwt100i3",
        "colab_type": "text"
      },
      "source": [
        "### LR on Character Level TF IDF Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LERKOjd0tnJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "a44e1721-63b3-4f2d-8378-35c8497059b1"
      },
      "source": [
        "# create LR Classifier\n",
        "LR_chars_tf_idf = linear_model.LogisticRegression()\n",
        "\n",
        "# train LR\n",
        "LR_chars_tf_idf.fit(xtrain_tfidf_ngram_chars, y_train)\n",
        "\n",
        "# get predictions\n",
        "preds = LR_chars_tf_idf.predict(xvalid_tfidf_ngram_chars)\n",
        "\n",
        "# accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"LR, Char Level TF-IDF: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR, Char Level TF-IDF:  0.9661016949152542\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        40\n",
            "           1       1.00      1.00      1.00        50\n",
            "           2       0.91      1.00      0.95       106\n",
            "           3       1.00      0.86      0.93        59\n",
            "           4       1.00      0.97      0.99        40\n",
            "\n",
            "    accuracy                           0.97       295\n",
            "   macro avg       0.98      0.96      0.97       295\n",
            "weighted avg       0.97      0.97      0.97       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6nXKPxQ113f",
        "colab_type": "text"
      },
      "source": [
        "## Support Vector Machines (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO_jEtc50y3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "6e841347-433b-4cf0-a428-ddb723dab154"
      },
      "source": [
        "# create SVM Classifier\n",
        "SVM_ngram_tf_idf = svm.SVC()\n",
        "\n",
        "# train SVM\n",
        "SVM_ngram_tf_idf.fit(xtrain_tfidf_ngram, y_train)\n",
        "\n",
        "# get predictions\n",
        "preds = SVM_ngram_tf_idf.predict(xvalid_tfidf_ngram)\n",
        "\n",
        "# accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"SVM, N-gram TF-IDF: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "SVM, N-gram TF-IDF:  0.9254237288135593\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.85      0.92        40\n",
            "           1       1.00      0.94      0.97        50\n",
            "           2       0.83      1.00      0.91       106\n",
            "           3       1.00      0.85      0.92        59\n",
            "           4       1.00      0.90      0.95        40\n",
            "\n",
            "    accuracy                           0.93       295\n",
            "   macro avg       0.97      0.91      0.93       295\n",
            "weighted avg       0.94      0.93      0.93       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tin8UcOV4NTO",
        "colab_type": "text"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnsTePXr3ciL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "09aca1d9-d73e-4d0c-f1f3-245a718dc615"
      },
      "source": [
        "# create RF Classifier\n",
        "RF_ngram_tf_idf = ensemble.RandomForestClassifier()\n",
        "\n",
        "# train RF\n",
        "RF_ngram_tf_idf.fit(xtrain_tfidf_ngram, y_train)\n",
        "\n",
        "# get predictions\n",
        "preds = RF_ngram_tf_idf.predict(xvalid_tfidf_ngram)\n",
        "\n",
        "# accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"RF, N-gram TF-IDF: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "RF, N-gram TF-IDF:  0.9050847457627119\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.78      0.87        40\n",
            "           1       1.00      0.92      0.96        50\n",
            "           2       0.79      1.00      0.88       106\n",
            "           3       1.00      0.83      0.91        59\n",
            "           4       1.00      0.88      0.93        40\n",
            "\n",
            "    accuracy                           0.91       295\n",
            "   macro avg       0.96      0.88      0.91       295\n",
            "weighted avg       0.92      0.91      0.91       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCQGDE0j4qtJ",
        "colab_type": "text"
      },
      "source": [
        "## XG Boost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruvKy28w4f5q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "7d6ddfa1-fafe-4285-d909-4e5082919fcf"
      },
      "source": [
        "# create XG Boost classifier\n",
        "xgb_count_vec = xgboost.XGBClassifier()\n",
        "\n",
        "# train XGB\n",
        "xgb_count_vec.fit(xtrain_count, y_train)\n",
        "\n",
        "# get predictions\n",
        "preds = xgb_count_vec.predict(xvalid_count)\n",
        "\n",
        "# accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"RF, N-gram TF-IDF: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "RF, N-gram TF-IDF:  0.9627118644067797\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        40\n",
            "           1       0.96      0.92      0.94        50\n",
            "           2       0.94      0.98      0.96       106\n",
            "           3       0.96      0.93      0.95        59\n",
            "           4       1.00      1.00      1.00        40\n",
            "\n",
            "    accuracy                           0.96       295\n",
            "   macro avg       0.97      0.96      0.97       295\n",
            "weighted avg       0.96      0.96      0.96       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaRujRdrTl-K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "a8f01242-5a52-47e5-c9ea-28508f6841a2"
      },
      "source": [
        "# create XG Boost classifier\n",
        "xgb_count_vec = xgboost.XGBClassifier()\n",
        "\n",
        "# train XGB\n",
        "xgb_count_vec.fit(xtrain_tfidf, y_train)\n",
        "\n",
        "# get predictions\n",
        "preds = xgb_count_vec.predict(xvalid_tfidf)\n",
        "\n",
        "# accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"RF, N-gram TF-IDF: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "RF, N-gram TF-IDF:  0.9661016949152542\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        40\n",
            "           1       0.96      0.96      0.96        50\n",
            "           2       0.95      0.98      0.97       106\n",
            "           3       0.96      0.92      0.94        59\n",
            "           4       0.98      1.00      0.99        40\n",
            "\n",
            "    accuracy                           0.97       295\n",
            "   macro avg       0.97      0.97      0.97       295\n",
            "weighted avg       0.97      0.97      0.97       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPhG-m3rS-k5",
        "colab_type": "text"
      },
      "source": [
        "## Shallow Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8e8ho3US9h8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "defed970-f269-4520-e1fc-1598f5a55474"
      },
      "source": [
        "def get_model(input_shape):\n",
        "    input_layer = layers.Input((input_shape, ), sparse=True)\n",
        "    \n",
        "    # create hidden layer\n",
        "    hidden_layer = layers.Dense(100, activation=\"relu\")(input_layer)\n",
        "    \n",
        "    # create output layer\n",
        "    output_layer = layers.Dense(5, activation=\"softmax\")(hidden_layer)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='sparse_categorical_crossentropy')\n",
        "    return model "
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayVCz3_-4zK3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "47ff67fd-879e-4794-8600-5866c7e13517"
      },
      "source": [
        "# create model and get its summary\n",
        "model = get_model(xtrain_tfidf_ngram.shape[1])\n",
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 5000)]            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               500100    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 505       \n",
            "=================================================================\n",
            "Total params: 500,605\n",
            "Trainable params: 500,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzoZcGXxZF_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "832440ed-99b0-443e-f77c-25ae5b368dd9"
      },
      "source": [
        "history = model.fit(xtrain_tfidf_ngram, y_train)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 3ms/step - loss: 1.5735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoOktcd9ZXzy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "dd3591eb-6d6c-4fae-e3d8-f7845672f129"
      },
      "source": [
        "# get predictions\n",
        "preds = model.predict(xvalid_tfidf_ngram)\n",
        "preds = preds.argmax(axis=-1)\n",
        "print(preds)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[2 0 2 3 2 2 1 2 1 0 2 2 2 3 2 3 4 1 4 1 2 3 3 0 2 2 2 2 2 2 2 4 3 1 4 2 2\n",
            " 1 4 2 1 2 1 2 0 1 2 2 3 2 2 0 2 4 1 2 2 2 2 3 2 2 2 4 2 2 1 0 3 2 4 2 1 1\n",
            " 0 2 2 1 2 1 2 1 3 2 1 2 3 2 1 1 2 2 3 2 2 2 2 4 2 2 0 4 2 2 2 3 2 2 3 3 1\n",
            " 3 1 2 2 0 2 1 3 1 2 2 2 2 3 2 2 0 0 2 0 2 2 2 2 1 2 4 0 1 2 1 2 2 1 4 2 2\n",
            " 2 2 2 0 3 2 0 0 2 2 4 4 1 2 4 1 0 2 1 2 1 2 2 2 0 0 2 2 2 2 4 1 2 0 1 0 0\n",
            " 2 2 2 2 1 2 2 2 1 0 2 2 2 2 2 2 4 1 2 3 2 1 2 2 3 2 2 2 1 3 1 1 2 4 3 1 1\n",
            " 1 2 2 2 2 3 3 4 1 3 2 2 2 2 3 0 2 2 2 1 2 2 2 2 4 4 2 2 2 2 3 1 2 2 2 1 4\n",
            " 2 0 2 2 0 3 2 2 3 4 4 2 4 2 2 4 1 1 2 2 2 1 2 2 3 2 0 2 2 2 3 2 0 3 4 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcB5ex2hZqow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "847f8cac-9cf2-41f3-fa60-1c77e712ad7f"
      },
      "source": [
        "# get accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"Shallow NN, N-gram TF-IDF: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Shallow NN, N-gram TF-IDF:  0.8271186440677966\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.70      0.82        40\n",
            "           1       0.98      1.00      0.99        50\n",
            "           2       0.68      1.00      0.81       106\n",
            "           3       1.00      0.56      0.72        59\n",
            "           4       1.00      0.68      0.81        40\n",
            "\n",
            "    accuracy                           0.83       295\n",
            "   macro avg       0.93      0.79      0.83       295\n",
            "weighted avg       0.88      0.83      0.82       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-o50dLwbEjq",
        "colab_type": "text"
      },
      "source": [
        "## Deep Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0zw0WhlbINZ",
        "colab_type": "text"
      },
      "source": [
        "### 1D CNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os_szC7laC3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f794b9c0-0c90-4a6e-f758-cc8e1fa2e90d"
      },
      "source": [
        "def create_cnn(inp_shape):\n",
        "    # Add an Input Layer\n",
        "    input_layer = layers.Input((inp_shape, ))\n",
        "\n",
        "    # Add the word embedding Layer\n",
        "    embedding_layer = layers.Embedding(input_dim=len(word_index) + 1, \n",
        "                                       output_dim=300, \n",
        "                                       weights=[embedding_matrix], \n",
        "                                       trainable=False)(input_layer)\n",
        "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    # Add the convolutional Layer\n",
        "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
        "\n",
        "    # Add the pooling Layer\n",
        "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
        "\n",
        "    # Add the output Layers\n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
        "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(5, activation=\"softmax\")(output_layer1)\n",
        "\n",
        "    # Compile the model\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='sparse_categorical_crossentropy')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hp8lPbTclce",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "c5ae5b78-9396-48f1-e181-f4bc4eca38c2"
      },
      "source": [
        "# model summary\n",
        "cnn_1d = create_cnn(train_seq_x.shape[1])\n",
        "cnn_1d.summary()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 200, 300)          3100200   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d (SpatialDr (None, 200, 300)          0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 198, 100)          90100     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 255       \n",
            "=================================================================\n",
            "Total params: 3,195,605\n",
            "Trainable params: 95,405\n",
            "Non-trainable params: 3,100,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBJomO0tc8IJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0c608f87-c088-4544-8abd-fb1960ff61d4"
      },
      "source": [
        "# training\n",
        "history = cnn_1d.fit(train_seq_x, y_train, epochs=1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 1s 74ms/step - loss: 1.6941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7WObWoxc8dB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "fbf2f177-6698-4f21-82d8-e0161b387cf1"
      },
      "source": [
        "# get predictions\n",
        "preds = cnn_1d.predict(valid_seq_x)\n",
        "preds = preds.argmax(axis=-1)\n",
        "print(preds)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[2 3 2 3 2 2 1 2 3 3 2 2 3 3 3 3 2 1 2 1 3 3 3 3 2 2 2 4 2 2 3 2 3 3 4 3 2\n",
            " 1 2 4 1 3 3 3 3 3 2 2 3 3 2 3 2 4 3 3 3 2 2 3 3 3 2 2 3 2 1 3 3 2 3 3 3 3\n",
            " 3 2 2 3 2 3 2 1 3 2 1 2 3 3 1 3 3 3 3 2 3 2 2 4 2 3 3 4 2 2 2 3 3 2 3 3 3\n",
            " 3 1 2 2 2 2 1 3 3 2 2 2 3 2 2 2 3 3 3 3 2 2 2 3 3 2 4 3 1 2 3 2 2 1 4 2 2\n",
            " 2 3 3 3 3 3 3 3 3 2 3 4 1 3 4 1 3 2 3 2 3 2 3 2 3 3 2 2 2 2 4 3 3 3 3 2 3\n",
            " 4 2 2 2 3 2 3 2 1 3 2 2 2 2 2 2 2 3 2 2 3 1 2 3 3 3 2 2 3 3 3 1 2 4 3 3 1\n",
            " 3 3 2 2 2 3 3 3 3 3 2 2 2 4 3 3 3 2 2 3 2 3 2 3 3 4 2 3 2 2 3 3 2 3 2 1 2\n",
            " 3 3 2 2 3 3 3 2 3 2 2 2 2 2 2 4 3 1 2 2 2 1 2 2 3 2 3 2 2 2 3 2 3 3 4 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqSGx4JPdH3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "5f1614b1-0f26-4571-ee6d-bf414e30e5af"
      },
      "source": [
        "# get accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"Deep 1D CNN, Sequenced Text: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Deep 1D CNN, Sequenced Text:  0.6677966101694915\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        40\n",
            "           1       1.00      0.46      0.63        50\n",
            "           2       0.83      0.97      0.90       106\n",
            "           3       0.41      0.92      0.57        59\n",
            "           4       1.00      0.42      0.60        40\n",
            "\n",
            "    accuracy                           0.67       295\n",
            "   macro avg       0.65      0.55      0.54       295\n",
            "weighted avg       0.69      0.67      0.62       295\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBJya5y8gytG",
        "colab_type": "text"
      },
      "source": [
        "### RNN - LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqDJGoHPgq-y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6e914d25-ab5d-45e2-873d-35ad00783919"
      },
      "source": [
        "def create_rnn_lstm(inp_shape):\n",
        "    # Add an Input Layer\n",
        "    input_layer = layers.Input((inp_shape, ))\n",
        "\n",
        "    # Add the word embedding Layer\n",
        "    embedding_layer = layers.Embedding(input_dim=len(word_index) + 1, \n",
        "                                       output_dim=300, \n",
        "                                       weights=[embedding_matrix], \n",
        "                                       trainable=False)(input_layer)\n",
        "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    # Add the LSTM Layer\n",
        "    lstm_layer = layers.Bidirectional(layers.LSTM(100))((embedding_layer))\n",
        "\n",
        "    # Add the output Layers\n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
        "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(5, activation=\"softmax\")(output_layer1)\n",
        "\n",
        "    # Compile the model\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='sparse_categorical_crossentropy')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fumQFvDShcWl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "6489c9fa-1df3-4a16-fbe8-05867abbacc5"
      },
      "source": [
        "# model summary\n",
        "rnn_lstm = create_rnn_lstm(train_seq_x.shape[1])\n",
        "rnn_lstm.summary()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 200, 300)          3100200   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 200, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 200)               320800    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                10050     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 255       \n",
            "=================================================================\n",
            "Total params: 3,431,305\n",
            "Trainable params: 331,105\n",
            "Non-trainable params: 3,100,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBHhsqWChsro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4215795e-8a5e-497a-b349-16cde2cd6563"
      },
      "source": [
        "# training\n",
        "history = rnn_lstm.fit(train_seq_x, y_train, epochs=1)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 6s 436ms/step - loss: 1.4967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4j9itR7h7Up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "b62ccbb2-2849-4616-ef49-1987fc15eb33"
      },
      "source": [
        "# get predictions\n",
        "preds = rnn_lstm.predict(valid_seq_x)\n",
        "preds = preds.argmax(axis=-1)\n",
        "print(preds)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 3 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2\n",
            " 1 2 2 3 2 2 3 2 1 2 2 2 2 2 2 2 2 2 3 2 2 2 3 2 2 2 2 2 2 2 2 3 2 2 2 1 2\n",
            " 2 2 2 1 2 2 2 1 3 2 1 2 2 0 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 1\n",
            " 2 1 2 2 2 2 1 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 3 2 2 2 3 1 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 4 1 2 2 1 2 2 1 2 2 2 3 2 2 2 2 2 2 2 2 2 3 0 3 0 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1\n",
            " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2\n",
            " 2 2 2 2 2 3 2 2 3 2 2 2 2 2 2 2 1 1 2 2 2 1 2 2 3 2 2 2 2 2 2 2 2 3 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngw8Rzkqh9-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "c4742fc7-a3e4-4a25-bf5c-3516dbd40031"
      },
      "source": [
        "# get accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"Deep RNN-LSTM, Sequenced Text: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Deep RNN-LSTM, Sequenced Text:  0.5220338983050847\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.07      0.14        40\n",
            "           1       1.00      0.50      0.67        50\n",
            "           2       0.43      1.00      0.61       106\n",
            "           3       0.86      0.32      0.47        59\n",
            "           4       1.00      0.03      0.05        40\n",
            "\n",
            "    accuracy                           0.52       295\n",
            "   macro avg       0.86      0.38      0.39       295\n",
            "weighted avg       0.77      0.52      0.45       295\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erFDrJeqjR6s",
        "colab_type": "text"
      },
      "source": [
        "### RNN - GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kh6wkOTEjcPN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4853cc8e-45d0-49c4-ce6f-562fe99cd577"
      },
      "source": [
        "def create_rnn_GRU(inp_shape):\n",
        "    # Add an Input Layer\n",
        "    input_layer = layers.Input((inp_shape, ))\n",
        "\n",
        "    # Add the word embedding Layer\n",
        "    embedding_layer = layers.Embedding(input_dim=len(word_index) + 1, \n",
        "                                       output_dim=300, \n",
        "                                       weights=[embedding_matrix], \n",
        "                                       trainable=False)(input_layer)\n",
        "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    # Add the GRU Layer\n",
        "    GRU_layer = layers.Bidirectional(layers.GRU(100))((embedding_layer))\n",
        "\n",
        "    # Add the output Layers\n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(GRU_layer)\n",
        "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(5, activation=\"softmax\")(output_layer1)\n",
        "\n",
        "    # Compile the model\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='sparse_categorical_crossentropy')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0hfa_VaRjcPv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "4be906c2-2bd7-4cfa-c077-96cb44e060ff"
      },
      "source": [
        "# model summary\n",
        "rnn_gru = create_rnn_lstm(train_seq_x.shape[1])\n",
        "rnn_gru.summary()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 200, 300)          3100200   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 200, 300)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 200)               320800    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 50)                10050     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 5)                 255       \n",
            "=================================================================\n",
            "Total params: 3,431,305\n",
            "Trainable params: 331,105\n",
            "Non-trainable params: 3,100,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0FHK9wUxjcQS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "32053bd6-d2b5-4ebe-8232-e2a8c740dfa3"
      },
      "source": [
        "# training\n",
        "history = rnn_gru.fit(train_seq_x, y_train, epochs=1)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 6s 432ms/step - loss: 1.4819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iHBdZDSSjcQe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "8da92931-cc09-45f0-caa4-df332e3e6939"
      },
      "source": [
        "# get predictions\n",
        "preds = rnn_gru.predict(valid_seq_x)\n",
        "preds = preds.argmax(axis=-1)\n",
        "print(preds)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 3 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2\n",
            " 1 2 2 1 2 2 1 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 1 2\n",
            " 2 2 2 1 2 2 2 1 1 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1\n",
            " 2 1 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1 2 1 2 2 2 4 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 1 2 1 2 1 2 2 2 2 2 2 2 2 2 2 4 1 2 2\n",
            " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 1 2 2 2 2 2 2 2 2 2 1 2 2 2 2 1\n",
            " 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2\n",
            " 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 1 1 2 2 2 1 2 2 3 2 2 2 2 1 2 2 2 1 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jLjLO8Z7jcQn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "7df99faa-e2e3-4390-a20c-c4180f09dc5f"
      },
      "source": [
        "# get accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"Deep RNN-LSTM, Sequenced Text: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Deep RNN-LSTM, Sequenced Text:  0.4711864406779661\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        40\n",
            "           1       0.69      0.62      0.65        50\n",
            "           2       0.43      0.99      0.60       106\n",
            "           3       1.00      0.03      0.07        59\n",
            "           4       0.50      0.03      0.05        40\n",
            "\n",
            "    accuracy                           0.47       295\n",
            "   macro avg       0.52      0.33      0.27       295\n",
            "weighted avg       0.54      0.47      0.34       295\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6imLTTqphyC",
        "colab_type": "text"
      },
      "source": [
        "### RCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYBCZ73tjuyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0a4f325c-fc05-4260-ba90-26a516e627d4"
      },
      "source": [
        "def create_rcnn(inp_shape):\n",
        "    # Add an Input Layer\n",
        "    input_layer = layers.Input((inp_shape, ))\n",
        "\n",
        "    # Add the word embedding Layer\n",
        "    embedding_layer = layers.Embedding(input_dim=len(word_index) + 1, \n",
        "                                       output_dim=300, \n",
        "                                       weights=[embedding_matrix], \n",
        "                                       trainable=False)(input_layer)\n",
        "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
        "\n",
        "    \n",
        "    # Add the recurrent layer\n",
        "    rnn_layer = layers.Bidirectional(layers.GRU(50, return_sequences=True))(embedding_layer)\n",
        "    \n",
        "    # Add the convolutional Layer\n",
        "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
        "\n",
        "    # Add the pooling Layer\n",
        "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
        "\n",
        "    # Add the output Layers\n",
        "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
        "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
        "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
        "\n",
        "    # Compile the model\n",
        "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
        "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iCywKjjsp8xL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "48e9eb9c-ecc9-4f3c-a104-37f40a8cbd0c"
      },
      "source": [
        "# model summary\n",
        "rcnn = create_rcnn(train_seq_x.shape[1])\n",
        "rcnn.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 200, 300)          3100200   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_3 (Spatial (None, 200, 300)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 198, 100)          90100     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 3,195,401\n",
            "Trainable params: 95,201\n",
            "Non-trainable params: 3,100,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bz8hMrl-p8yE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e25abcf-01cc-4a57-b4b7-22946f2e77b6"
      },
      "source": [
        "# training\n",
        "history = rcnn.fit(train_seq_x, y_train, epochs=1)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 1s 73ms/step - loss: -6.1059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aQ4fHMTMp8yY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "74cd5608-feb6-41db-98bc-3b27481da899"
      },
      "source": [
        "# get predictions\n",
        "preds = rcnn.predict(valid_seq_x)\n",
        "preds = preds.argmax(axis=-1)\n",
        "print(preds)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N9gG5AVqp8yj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "bbd06edc-5185-4ec7-bdc6-6b401e20878b"
      },
      "source": [
        "# get accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, preds)\n",
        "print(\"Deep RNN-LSTM, Sequenced Text: \", accuracy)\n",
        "print(metrics.classification_report(y_test, preds))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Deep RNN-LSTM, Sequenced Text:  0.13559322033898305\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      1.00      0.24        40\n",
            "           1       0.00      0.00      0.00        50\n",
            "           2       0.00      0.00      0.00       106\n",
            "           3       0.00      0.00      0.00        59\n",
            "           4       0.00      0.00      0.00        40\n",
            "\n",
            "    accuracy                           0.14       295\n",
            "   macro avg       0.03      0.20      0.05       295\n",
            "weighted avg       0.02      0.14      0.03       295\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}