{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Pipeline Example\n",
    "* [Resource](https://medium.com/vickdata/a-simple-guide-to-scikit-learn-pipelines-4ac0d974bdcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Gender                object\nMarried               object\nDependents            object\nEducation             object\nSelf_Employed         object\nApplicantIncome        int64\nCoapplicantIncome    float64\nLoanAmount           float64\nLoan_Amount_Term     float64\nCredit_History       float64\nProperty_Area         object\nLoan_Status           object\ndtype: object"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "## Improrting data\n",
    "import pandas as pd\n",
    "train = pd.read_csv(r'.\\dataset\\train_ctrUa4K.csv')\n",
    "test = pd.read_csv(r'.\\dataset\\test_lAUu6dG.csv')\n",
    "train = train.drop('Loan_ID', axis='columns')\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into train and test\n",
    "X = train.drop('Loan_Status', axis=1)\n",
    "y = train['Loan_Status']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X_train.shape : (491, 11)\nX_test.shape : (123, 11)\ny_train.shape : (491,)\ny_test.shape : (123,)\n"
    }
   ],
   "source": [
    "# sanity check\n",
    "print(f\"X_train.shape : {X_train.shape}\")\n",
    "print(f\"X_test.shape : {X_test.shape}\")\n",
    "print(f\"y_train.shape : {y_train.shape}\")\n",
    "print(f\"y_test.shape : {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')), # impute missing values by column median\n",
    "        ('scaler', StandardScaler()) # scale values to 0-1 range\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')), # impute missing values with 'missing'\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "numeric_features: Index(['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n       'Loan_Amount_Term', 'Credit_History'],\n      dtype='object')\ncategorical_features: Index(['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',\n       'Property_Area'],\n      dtype='object')\n"
    }
   ],
   "source": [
    "# get numeric and categorical features\n",
    "numeric_features = train.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(f\"numeric_features: {numeric_features}\")\n",
    "categorical_features = train.select_dtypes(include=['object']).drop(['Loan_Status'], axis=1).columns\n",
    "print(f\"categorical_features: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use column transformer to preprocess different columns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.08391466, 0.18066742, 1.35547238, 0.28761093, 0.40776315,\n        0.        , 1.        , 0.        , 0.        , 1.        ,\n        0.        , 1.        , 0.        , 0.        , 0.        ,\n        0.        , 1.        , 0.        , 1.        , 0.        ,\n        0.        , 0.        , 1.        , 0.        ]])"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('preprocessor',\n                 ColumnTransformer(n_jobs=None, remainder='drop',\n                                   sparse_threshold=0.3,\n                                   transformer_weights=None,\n                                   transformers=[('num',\n                                                  Pipeline(memory=None,\n                                                           steps=[('imputer',\n                                                                   SimpleImputer(add_indicator=False,\n                                                                                 copy=True,\n                                                                                 fill_value=None,\n                                                                                 missing_values=nan,\n                                                                                 strategy='median',\n                                                                                 verbose=0)),\n                                                                  ('scaler',\n                                                                   StandardScaler(copy=True,\n                                                                                  with_mean...\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=None, max_features='auto',\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=2,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=100, n_jobs=None,\n                                        oob_score=False, random_state=None,\n                                        verbose=0, warm_start=False))],\n         verbose=False)"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# Creating a random forest classifier and fitting it to data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(491, 11)\n123\n"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "# print(len(preds))\n",
    "print(len(y_test.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['N' 'Y' 'Y' 'Y' 'N' 'N' 'Y' 'N' 'Y' 'Y']\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7723577235772358"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "preds = rf.predict(X_train)\n",
    "print(preds[:10])\n",
    "# print(preds, len(preds), len(y_test), y_test)\n",
    "rf.score(X_test, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'classifier__criterion': 'entropy', 'classifier__max_depth': 6, 'classifier__max_features': 'auto', 'classifier__n_estimators': 200}\n0.8145743145743145\n"
    }
   ],
   "source": [
    "# Using Gridsearch for hyperparameter tuning\n",
    "param_grid = { \n",
    "    'classifier__n_estimators': [200, 500],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'classifier__max_depth' : [4,5,6,7,8],\n",
    "    'classifier__criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "CV = GridSearchCV(rf, param_grid, n_jobs= -1)\n",
    "                  \n",
    "CV.fit(X_train, y_train)  \n",
    "print(CV.best_params_)    \n",
    "print(CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training Score: 0.8472505091649695\nTesting Score: 0.7886178861788617\n"
    }
   ],
   "source": [
    "# Create a new classifer using the best parameters\n",
    "# Creating a random forest classifier and fitting it to data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(criterion='entropy', \n",
    "                                              max_depth=7,\n",
    "                                              max_features='log2',\n",
    "                                              n_estimators=500))\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print(f\"Training Score: {rf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Score: {rf.score(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the above process can also be done in a different way, using make_pipeline and make_column_transformer, key difference being, we won't need to pass name of the process. More about it can be find [here](https://jorisvandenbossche.github.io/blog/2018/05/28/scikit-learn-columntransformer/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[8.39146643e-02, 1.80667417e-01, 1.34913392e+00, 2.95122167e-01,\n        3.19909943e-16, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n        1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00]])"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "preprocessor2 = make_column_transformer(\n",
    "    (\n",
    "        # numeric_features,\n",
    "        make_pipeline(\n",
    "            SimpleImputer(), # left empty, will be used in grid search\n",
    "            StandardScaler()\n",
    "        ),\n",
    "        numeric_features\n",
    "    ),\n",
    "    (\n",
    "        # categorical_features,\n",
    "        make_pipeline(\n",
    "            SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "            OneHotEncoder(handle_unknown='ignore')\n",
    "        ),\n",
    "        categorical_features\n",
    "    )\n",
    ")\n",
    "\n",
    "# check one of the preprocessed output\n",
    "preprocessor2.fit_transform(X_train)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training Score: 1.0\nTesting Score: 0.7560975609756098\n"
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "rf_model = make_pipeline(\n",
    "    preprocessor2,\n",
    "    RandomForestClassifier() # This will clearly overfit\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(f\"Training Score: {rf_model.score(X_train, y_train)}\")\n",
    "print(f\"Testing Score: {rf_model.score(X_test, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GridSearch in Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "memory\nsteps\nverbose\ncolumntransformer\nrandomforestclassifier\ncolumntransformer__n_jobs\ncolumntransformer__remainder\ncolumntransformer__sparse_threshold\ncolumntransformer__transformer_weights\ncolumntransformer__transformers\ncolumntransformer__verbose\ncolumntransformer__pipeline-1\ncolumntransformer__pipeline-2\ncolumntransformer__pipeline-1__memory\ncolumntransformer__pipeline-1__steps\ncolumntransformer__pipeline-1__verbose\ncolumntransformer__pipeline-1__simpleimputer\ncolumntransformer__pipeline-1__standardscaler\ncolumntransformer__pipeline-1__simpleimputer__add_indicator\ncolumntransformer__pipeline-1__simpleimputer__copy\ncolumntransformer__pipeline-1__simpleimputer__fill_value\ncolumntransformer__pipeline-1__simpleimputer__missing_values\ncolumntransformer__pipeline-1__simpleimputer__strategy\ncolumntransformer__pipeline-1__simpleimputer__verbose\ncolumntransformer__pipeline-1__standardscaler__copy\ncolumntransformer__pipeline-1__standardscaler__with_mean\ncolumntransformer__pipeline-1__standardscaler__with_std\ncolumntransformer__pipeline-2__memory\ncolumntransformer__pipeline-2__steps\ncolumntransformer__pipeline-2__verbose\ncolumntransformer__pipeline-2__simpleimputer\ncolumntransformer__pipeline-2__onehotencoder\ncolumntransformer__pipeline-2__simpleimputer__add_indicator\ncolumntransformer__pipeline-2__simpleimputer__copy\ncolumntransformer__pipeline-2__simpleimputer__fill_value\ncolumntransformer__pipeline-2__simpleimputer__missing_values\ncolumntransformer__pipeline-2__simpleimputer__strategy\ncolumntransformer__pipeline-2__simpleimputer__verbose\ncolumntransformer__pipeline-2__onehotencoder__categories\ncolumntransformer__pipeline-2__onehotencoder__drop\ncolumntransformer__pipeline-2__onehotencoder__dtype\ncolumntransformer__pipeline-2__onehotencoder__handle_unknown\ncolumntransformer__pipeline-2__onehotencoder__sparse\nrandomforestclassifier__bootstrap\nrandomforestclassifier__ccp_alpha\nrandomforestclassifier__class_weight\nrandomforestclassifier__criterion\nrandomforestclassifier__max_depth\nrandomforestclassifier__max_features\nrandomforestclassifier__max_leaf_nodes\nrandomforestclassifier__max_samples\nrandomforestclassifier__min_impurity_decrease\nrandomforestclassifier__min_impurity_split\nrandomforestclassifier__min_samples_leaf\nrandomforestclassifier__min_samples_split\nrandomforestclassifier__min_weight_fraction_leaf\nrandomforestclassifier__n_estimators\nrandomforestclassifier__n_jobs\nrandomforestclassifier__oob_score\nrandomforestclassifier__random_state\nrandomforestclassifier__verbose\nrandomforestclassifier__warm_start\n"
    }
   ],
   "source": [
    "# create an empty parameter grid \n",
    "param_grid = {}\n",
    "# Get a list of parameters that we can tune\n",
    "grid_clf = GridSearchCV(rf_model, param_grid, cv=10, iid=False)\n",
    "for val in grid_clf.estimator.get_params().keys():\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a parameter grid based on the parameters \n",
    "param_grid = {\n",
    "    'columntransformer__pipeline-1__simpleimputer__strategy': ['mean', 'median'],\n",
    "    'randomforestclassifier__n_estimators': [200, 500],\n",
    "    'randomforestclassifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'randomforestclassifier__max_depth' : [4,5,6,7,8],\n",
    "    'randomforestclassifier__criterion' :['gini', 'entropy']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=3, error_score=nan,\n             estimator=Pipeline(memory=None,\n                                steps=[('columntransformer',\n                                        ColumnTransformer(n_jobs=None,\n                                                          remainder='drop',\n                                                          sparse_threshold=0.3,\n                                                          transformer_weights=None,\n                                                          transformers=[('pipeline-1',\n                                                                         Pipeline(memory=None,\n                                                                                  steps=[('simpleimputer',\n                                                                                          SimpleImputer(add_indicator=False,\n                                                                                                        copy=True,\n                                                                                                        fill_value=None,\n                                                                                                        missing_values=nan,\n                                                                                                        strategy='me...\n             param_grid={'columntransformer__pipeline-1__simpleimputer__strategy': ['mean',\n                                                                                    'median'],\n                         'randomforestclassifier__criterion': ['gini',\n                                                               'entropy'],\n                         'randomforestclassifier__max_depth': [4, 5, 6, 7, 8],\n                         'randomforestclassifier__max_features': ['auto',\n                                                                  'sqrt',\n                                                                  'log2'],\n                         'randomforestclassifier__n_estimators': [200, 500]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n             scoring=None, verbose=0)"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "grid_clf = GridSearchCV(estimator=rf_model, \n",
    "                        param_grid=param_grid, \n",
    "                        cv=3, # kfolds = 3\n",
    "                        n_jobs=-1, # use all processors\n",
    "                        refit=True, # fit best classifier on train data at end, default=True\n",
    "                        return_train_score=True)\n",
    "grid_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'columntransformer__pipeline-1__simpleimputer__strategy': 'mean', 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 7, 'randomforestclassifier__max_features': 'log2', 'randomforestclassifier__n_estimators': 200}\n"
    }
   ],
   "source": [
    "# print best model hyperparameters\n",
    "print(grid_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Pipeline(memory=None,\n         steps=[('columntransformer',\n                 ColumnTransformer(n_jobs=None, remainder='drop',\n                                   sparse_threshold=0.3,\n                                   transformer_weights=None,\n                                   transformers=[('pipeline-1',\n                                                  Pipeline(memory=None,\n                                                           steps=[('simpleimputer',\n                                                                   SimpleImputer(add_indicator=False,\n                                                                                 copy=True,\n                                                                                 fill_value=None,\n                                                                                 missing_values=nan,\n                                                                                 strategy='mean',\n                                                                                 verbose=0)),\n                                                                  ('standardscaler',\n                                                                   StandardSc...\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='entropy',\n                                        max_depth=7, max_features='log2',\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=2,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=200, n_jobs=None,\n                                        oob_score=False, random_state=None,\n                                        verbose=0, warm_start=False))],\n         verbose=False)\n"
    }
   ],
   "source": [
    "# print parameters of best model\n",
    "best_model = grid_clf.best_estimator_\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "best model from grid search:  0.7886178861788617\n"
    }
   ],
   "source": [
    "# print accuracy of best model on test data\n",
    "print(\"best model from grid search: \", best_model.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['best_model.joblib']"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "# save the best model\n",
    "import joblib\n",
    "joblib.dump(best_model, 'best_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved model\n",
    "loaded_model = joblib.load('best_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.7886178861788617\n"
    }
   ],
   "source": [
    "# checking accuracy score via loaded model\n",
    "print(loaded_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as that of best_model. So, SUCCESS!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bituditmvirtualenv9e229ad653d649b7aeefad2186c03752",
   "display_name": "Python 3.7.3 64-bit ('uditm': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}