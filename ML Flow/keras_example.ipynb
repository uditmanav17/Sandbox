{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains and evaluate a simple MLP on the Reuters newswire topic classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# The following import and function call are the only additions to code required\n",
    "# to automatically log metrics and parameters to MLflow.\n",
    "import mlflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'reuters_keras0' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "# mlflow server --backend-store-uri mlruns/ --default-artifact-root mlruns/ --host 0.0.0.0\n",
    "remote_server_uri = \"http://DESKTOP-BPV4P4B:5000\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env\n",
    "\n",
    "exp_name = \"reuters_keras0\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.keras.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "batch_size = 64\n",
    "epochs = 7\n",
    "\n",
    "mlflow.log_params({\"max_words\": max_words, \"batch_size\": batch_size, \"epochs\": epochs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Train Shape - (8982,)\n",
      "Test Shape - (2246,)\n",
      "46 classes\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words,\n",
    "                                                         test_split=0.2)\n",
    "\n",
    "print(f\"Train Shape - {x_train.shape}\")\n",
    "print(f\"Test Shape - {x_test.shape}\")\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing sequence data...\n",
      "x_train shape: (8982, 1000)\n",
      "x_test shape: (2246, 1000)\n"
     ]
    }
   ],
   "source": [
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape (brfore): (8982,)\n",
      "y_test shape (before): (2246,)\n",
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n"
     ]
    }
   ],
   "source": [
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "print('y_train shape (brfore):', y_train.shape)\n",
    "print('y_test shape (before):', y_test.shape)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "print('Building model...')\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "loss='categorical_crossentropy'\n",
    "optimizer='adam'\n",
    "mlflow.log_params({\"loss_type\": loss})\n",
    "\n",
    "model.compile(loss=loss,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "127/127 [==============================] - 2s 18ms/step - loss: 1.5477 - accuracy: 0.6550 - val_loss: 1.1532 - val_accuracy: 0.7508\n",
      "Epoch 2/7\n",
      "127/127 [==============================] - 2s 18ms/step - loss: 0.8858 - accuracy: 0.7971 - val_loss: 0.9716 - val_accuracy: 0.7831\n",
      "Epoch 3/7\n",
      "127/127 [==============================] - 2s 17ms/step - loss: 0.6463 - accuracy: 0.8458 - val_loss: 0.8896 - val_accuracy: 0.7942\n",
      "Epoch 4/7\n",
      "127/127 [==============================] - 2s 18ms/step - loss: 0.4867 - accuracy: 0.8851 - val_loss: 0.8576 - val_accuracy: 0.8065\n",
      "Epoch 5/7\n",
      "127/127 [==============================] - 2s 18ms/step - loss: 0.3891 - accuracy: 0.9056 - val_loss: 0.8721 - val_accuracy: 0.8076\n",
      "Epoch 6/7\n",
      "127/127 [==============================] - 2s 18ms/step - loss: 0.3294 - accuracy: 0.9169 - val_loss: 0.8739 - val_accuracy: 0.8109\n",
      "Epoch 7/7\n",
      "127/127 [==============================] - 2s 18ms/step - loss: 0.2747 - accuracy: 0.9306 - val_loss: 0.8896 - val_accuracy: 0.8131\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.547703</td>\n",
       "      <td>0.654955</td>\n",
       "      <td>1.153225</td>\n",
       "      <td>0.750834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.885829</td>\n",
       "      <td>0.797105</td>\n",
       "      <td>0.971569</td>\n",
       "      <td>0.783092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.646252</td>\n",
       "      <td>0.845849</td>\n",
       "      <td>0.889596</td>\n",
       "      <td>0.794216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.486690</td>\n",
       "      <td>0.885067</td>\n",
       "      <td>0.857558</td>\n",
       "      <td>0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.389071</td>\n",
       "      <td>0.905604</td>\n",
       "      <td>0.872100</td>\n",
       "      <td>0.807564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.329375</td>\n",
       "      <td>0.916863</td>\n",
       "      <td>0.873904</td>\n",
       "      <td>0.810901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.274686</td>\n",
       "      <td>0.930595</td>\n",
       "      <td>0.889596</td>\n",
       "      <td>0.813126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  1.547703  0.654955  1.153225      0.750834\n",
       "1  0.885829  0.797105  0.971569      0.783092\n",
       "2  0.646252  0.845849  0.889596      0.794216\n",
       "3  0.486690  0.885067  0.857558      0.806452\n",
       "4  0.389071  0.905604  0.872100      0.807564\n",
       "5  0.329375  0.916863  0.873904      0.810901\n",
       "6  0.274686  0.930595  0.889596      0.813126"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is missing in the log? \n",
    "import pandas as pd\n",
    "epoch_data = history.history\n",
    "epoch_data = pd.DataFrame(epoch_data)\n",
    "epoch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/36 [..............................] - ETA: 0s - loss: 0.9324 - accuracy: 0.7969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uditm\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:523: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  tensor_proto.tensor_content = nparray.tostring()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 5ms/step - loss: 0.8822 - accuracy: 0.7965\n",
      "Test score: 0.882178008556366\n",
      "Test accuracy: 0.7965271472930908\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "mlflow.log_metrics({\"test_accuarcy\": score[1], \"test_loss\": score[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.keras.log_model(model, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
